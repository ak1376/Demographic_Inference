{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './data/*.vcf.gz': No such file or directory\n",
      "rm: cannot remove './data/*.h5': No such file or directory\n",
      "2024-10-16 14:58:26,806\tINFO worker.py:1781 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running msprime and writing vcfs\n",
      "writing samples and recombination map\n",
      "parsing LD statistics in parallel\n",
      "\u001b[36m(get_LD_stats pid=2041013)\u001b[0m   finished rep 24 in 83 seconds\n",
      "\u001b[36m(get_LD_stats pid=2042348)\u001b[0m   finished rep 11 in 88 seconds\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2037212)\u001b[0m   finished rep 86 in 93 seconds\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2041331)\u001b[0m   finished rep 44 in 98 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2037328)\u001b[0m   finished rep 87 in 103 seconds\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2042022)\u001b[0m   finished rep 27 in 109 seconds\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2041282)\u001b[0m   finished rep 32 in 114 seconds\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "computing mean and varcov matrix from LD statistics sums\n",
      "computing bootstrap replicates of mean statistics (for confidence intervals\n",
      "running inference\n",
      "Simulated parameters:\n",
      "  N(deme0)         :  3438.0\n",
      "  N(deme1)         :  9082.0\n",
      "  Div. time (gen)  :  1805.0\n",
      "  Migration rate   :  0.000019\n",
      "  N(ancestral)     :  14586.0\n",
      "best fit parameters:\n",
      "  N(deme0)         :  3333.0\n",
      "  N(deme1)         :  8653.2\n",
      "  Div. time (gen)  :  1799.9\n",
      "  Migration rate   :  0.000024\n",
      "  N(ancestral)     :  15602.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script uses msprime to simulate under an isolation with migration model,\n",
    "writing the outputs to VCF. We'll simulate a small dataset: 100 x 1Mb regions,\n",
    "each with recombination and mutation rates of 1.5e-8. We'll then use moments\n",
    "to compute LD statistics from each of the 100 replicates to compute statistic\n",
    "means and variances/covariances. These are then used to refit the simulated\n",
    "model using moments.LD, and then we use bootstrapped datasets to estimate\n",
    "confidence intervals.\n",
    "\n",
    "The demographic model is a population of size 10,000 that splits into a\n",
    "population of size 2,000 and a population of size 20,000. The split occurs\n",
    "1,500 generations ago followed by symmetric migration at rate 1e-4.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import msprime\n",
    "import moments\n",
    "import demes\n",
    "import ray\n",
    "import json\n",
    "\n",
    "assert msprime.__version__ >= \"1\"\n",
    "\n",
    "if not os.path.isdir(\"./data/\"):\n",
    "    os.makedirs(\"./data/\")\n",
    "os.system(\"rm ./data/*.vcf.gz\")\n",
    "os.system(\"rm ./data/*.h5\")\n",
    "\n",
    "upper_bound_params = {\n",
    "    \"t_split\": 5000, \n",
    "    \"m\": 1e-4,\n",
    "    \"N1\": 10000,\n",
    "    \"N2\": 10000,\n",
    "    \"Na\": 20000\n",
    "}\n",
    "\n",
    "lower_bound_params =  {\n",
    "    \"t_split\": 100, \n",
    "    \"m\": 1e-8,\n",
    "    \"N1\": 100,\n",
    "    \"N2\": 100,\n",
    "    \"Na\": 10000\n",
    "\n",
    "}\n",
    "\n",
    "def sample_params():\n",
    "    sampled_params = {}\n",
    "    for key in lower_bound_params:\n",
    "        lower_bound = lower_bound_params[key]\n",
    "        upper_bound = upper_bound_params[key]\n",
    "        sampled_value = np.random.uniform(lower_bound, upper_bound)\n",
    "\n",
    "        # Initialize adjusted_value with sampled_value by default\n",
    "        adjusted_value = sampled_value\n",
    "\n",
    "        # Check if the sampled parameter is equal to the mean of the uniform distribution\n",
    "        mean_value = (lower_bound + upper_bound) / 2\n",
    "        if sampled_value == mean_value:\n",
    "            # Add a small random value to avoid exact mean, while keeping within bounds\n",
    "            adjustment = np.random.uniform(-0.1 * (upper_bound - lower_bound), 0.1 * (upper_bound - lower_bound))\n",
    "            adjusted_value = sampled_value + adjustment\n",
    "            # Ensure the adjusted value is still within the bounds\n",
    "            adjusted_value = max(min(adjusted_value, upper_bound), lower_bound)\n",
    "\n",
    "        # Assign adjusted_value to sampled_params\n",
    "        if key == \"m\":\n",
    "            sampled_params[key] = adjusted_value\n",
    "        else:\n",
    "            sampled_params[key] = int(adjusted_value)\n",
    "\n",
    "    return sampled_params\n",
    "\n",
    "def demographic_model(sampled_params):\n",
    "\n",
    "    # Unpack the sampled parameters\n",
    "    Na, N1, N2, m, t_split = (\n",
    "        sampled_params[\"Na\"],  # Effective population size of the ancestral population\n",
    "        sampled_params[\"N1\"],  # Size of population 1 after split\n",
    "        sampled_params[\"N2\"],  # Size of population 2 after split\n",
    "        sampled_params[\"m\"],   # Migration rate between populations\n",
    "        sampled_params[\"t_split\"],  # Time of the population split (in generations)\n",
    "    )\n",
    "\n",
    "    b = demes.Builder()\n",
    "    b.add_deme(\"Na\", epochs=[dict(start_size=Na, end_time=t_split)])\n",
    "    b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=N1)])\n",
    "    b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=N2)])\n",
    "    b.add_migration(demes=[\"N1\", \"N2\"], rate=m)\n",
    "    g = b.resolve()\n",
    "    return g\n",
    "\n",
    "# def demographic_model():\n",
    "#     b = demes.Builder()\n",
    "#     b.add_deme(\"Na\", epochs=[dict(start_size=18575, end_time=1408)])\n",
    "#     b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=617)])\n",
    "#     b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=4559)])\n",
    "#     b.add_migration(demes=[\"N1\", \"N2\"], rate=7.701758925243914e-05)\n",
    "#     g = b.resolve()\n",
    "#     return g\n",
    "\n",
    "# def run_msprime_replicates(experiment_config, num_reps=100):\n",
    "#     # Set up the demography from demes\n",
    "#     g = demographic_model()\n",
    "#     demog = msprime.Demography.from_demes(g)\n",
    "\n",
    "#     # Dynamically define the samples using msprime.SampleSet, based on the sample_sizes dictionary\n",
    "#     samples = [\n",
    "#         msprime.SampleSet(sample_size, population=pop_name, ploidy=1)\n",
    "#         for pop_name, sample_size in experiment_config['num_samples'].items()\n",
    "#     ]\n",
    "\n",
    "#     tree_sequences = msprime.sim_ancestry(\n",
    "#         samples,\n",
    "#         demography=demog,\n",
    "#         sequence_length=experiment_config['genome_length'],\n",
    "#         recombination_rate=experiment_config['recombination_rate'],\n",
    "#         num_replicates=num_reps,\n",
    "#         random_seed=42,\n",
    "#     )\n",
    "#     for ii, ts in enumerate(tree_sequences):\n",
    "#         ts = msprime.sim_mutations(ts, rate=experiment_config['mutation_rate'], random_seed=ii + 1)\n",
    "#         vcf_name = \"./data/split_mig.{0}.vcf\".format(ii)\n",
    "#         with open(vcf_name, \"w+\") as fout:\n",
    "#             ts.write_vcf(fout, allow_position_zero=True)\n",
    "#         os.system(f\"gzip {vcf_name}\")\n",
    "\n",
    "\n",
    "def run_msprime_replicates(sampled_params, experiment_config):\n",
    "\n",
    "    g = demographic_model(sampled_params)\n",
    "    demog = msprime.Demography.from_demes(g)\n",
    "    tree_sequences = msprime.sim_ancestry(\n",
    "        {\"N1\": experiment_config['num_samples']['N1'], \"N2\": experiment_config['num_samples']['N2']},\n",
    "        demography=demog,\n",
    "        sequence_length=experiment_config['genome_length'],\n",
    "        recombination_rate=experiment_config['recombination_rate'],\n",
    "        num_replicates=experiment_config['num_reps'],\n",
    "        random_seed=experiment_config['seed'],\n",
    "    )\n",
    "    for ii, ts in enumerate(tree_sequences):\n",
    "        ts = msprime.sim_mutations(ts, rate=experiment_config['mutation_rate'], random_seed=ii + 1)\n",
    "        vcf_name = \"./data/split_mig.{0}.vcf\".format(ii)\n",
    "        with open(vcf_name, \"w+\") as fout:\n",
    "            ts.write_vcf(fout, allow_position_zero=True)\n",
    "        os.system(f\"gzip {vcf_name}\")\n",
    "\n",
    "def write_samples_and_rec_map(experiment_config):\n",
    "\n",
    "    # Define the file paths\n",
    "    samples_file = \"./data/samples.txt\"\n",
    "    flat_map_file =\"./data/flat_map.txt\"\n",
    "\n",
    "    # Open and write the sample file\n",
    "    with open(samples_file, \"w+\") as fout:\n",
    "        fout.write(\"sample\\tpop\\n\")\n",
    "\n",
    "        # Dynamically define samples based on the num_samples dictionary\n",
    "        sample_idx = 0  # Initialize sample index\n",
    "        for pop_name, sample_size in experiment_config['num_samples'].items():\n",
    "            for _ in range(sample_size):\n",
    "                fout.write(f\"tsk_{sample_idx}\\t{pop_name}\\n\")\n",
    "                sample_idx += 1\n",
    "\n",
    "    # Write the recombination map file\n",
    "    with open(flat_map_file, \"w+\") as fout:\n",
    "        fout.write(\"pos\\tMap(cM)\\n\")\n",
    "        fout.write(\"0\\t0\\n\")\n",
    "        fout.write(f\"{experiment_config['genome_length']}\\t{experiment_config['recombination_rate'] * experiment_config['genome_length'] * 100}\\n\")\n",
    "\n",
    "# def write_samples_and_rec_map(L=1000000, r=1.5e-8, n=18):\n",
    "#     # samples file\n",
    "#     with open(\"./data/samples.txt\", \"w+\") as fout:\n",
    "#         fout.write(\"sample\\tpop\\n\")\n",
    "#         for jj in range(2):\n",
    "#             for ii in range(n):\n",
    "#                 fout.write(f\"tsk_{jj * n + ii}\\tdeme{jj}\\n\")\n",
    "#     # recombination map\n",
    "#     with open(\"./data/flat_map.txt\", \"w+\") as fout:\n",
    "#         fout.write(\"pos\\tMap(cM)\\n\")\n",
    "#         fout.write(\"0\\t0\\n\")\n",
    "#         fout.write(f\"{L}\\t{r * L * 100}\\n\")\n",
    "\n",
    "# Define your function with Ray's remote decorator\n",
    "@ray.remote\n",
    "def get_LD_stats(rep_ii, r_bins):\n",
    "    vcf_file = f\"./data/split_mig.{rep_ii}.vcf.gz\"\n",
    "    time1 = time.time()\n",
    "    ld_stats = moments.LD.Parsing.compute_ld_statistics(\n",
    "        vcf_file,\n",
    "        rec_map_file=\"./data/flat_map.txt\",\n",
    "        pop_file=\"./data/samples.txt\",\n",
    "        pops=[\"N1\", \"N2\"],\n",
    "        r_bins=r_bins,\n",
    "        report=False,\n",
    "    )\n",
    "    time2 = time.time()\n",
    "    print(\"  finished rep\", rep_ii, \"in\", int(time2 - time1), \"seconds\")\n",
    "    return ld_stats\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_reps = 100\n",
    "    # define the bin edges\n",
    "    r_bins = np.array([0, 1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3])\n",
    "\n",
    "    with open(\"/sietch_colab/akapoor/Demographic_Inference/experiment_config.json\") as f:\n",
    "        experiment_config = json.load(f)\n",
    "\n",
    "\n",
    "    # Initialize Ray\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    # Sample parameters\n",
    "    sampled_params = sample_params()\n",
    "\n",
    "    print(\"running msprime and writing vcfs\")\n",
    "    run_msprime_replicates(sampled_params, experiment_config)\n",
    "    # run_msprime_replicates(experiment_config=experiment_config, num_reps=num_reps)\n",
    "\n",
    "    print(\"writing samples and recombination map\")\n",
    "    write_samples_and_rec_map(experiment_config=experiment_config)\n",
    "\n",
    "    print(\"parsing LD statistics in parallel\")\n",
    "    # Submit tasks to Ray in parallel using .remote()\n",
    "    futures = [get_LD_stats.remote(ii, r_bins) for ii in range(num_reps)]\n",
    "    # Gather results with ray.get() to collect them once the tasks are finished\n",
    "    ld_stats = ray.get(futures)\n",
    "    # Optionally, you can convert the list of results into a dictionary with indices\n",
    "    ld_stats_dict = {ii: result for ii, result in enumerate(ld_stats)}\n",
    "\n",
    "    print(\"computing mean and varcov matrix from LD statistics sums\")\n",
    "    mv = moments.LD.Parsing.bootstrap_data(ld_stats_dict)\n",
    "    with open(f\"./data/means.varcovs.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(mv, fout)\n",
    "    print(\n",
    "        \"computing bootstrap replicates of mean statistics (for confidence intervals\"\n",
    "    )\n",
    "    all_boot = moments.LD.Parsing.get_bootstrap_sets(ld_stats_dict)\n",
    "    with open(f\"./data/bootstrap_sets.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(all_boot, fout)\n",
    "    os.system(\"rm ./data/*.vcf.gz\")\n",
    "    os.system(\"rm ./data/*.h5\")\n",
    "\n",
    "# print(\"computing expectations under the model\")\n",
    "g = demographic_model(sampled_params)\n",
    "# y = moments.Demes.LD(g, sampled_demes=[\"deme0\", \"deme1\"], rho=4 * 10000 * r_bins)\n",
    "# y = moments.LD.LDstats(\n",
    "#     [(y_l + y_r) / 2 for y_l, y_r in zip(y[:-2], y[1:-1])] + [y[-1]],\n",
    "#     num_pops=y.num_pops,\n",
    "#     pop_ids=y.pop_ids,\n",
    "# )\n",
    "# y = moments.LD.Inference.sigmaD2(y)\n",
    "\n",
    "# plot simulated data vs expectations under the model\n",
    "# fig = moments.LD.Plotting.plot_ld_curves_comp(\n",
    "#     y,\n",
    "#     mv[\"means\"][:-1],\n",
    "#     mv[\"varcovs\"][:-1],\n",
    "#     rs=r_bins,\n",
    "#     stats_to_plot=[\n",
    "#         [\"DD_0_0\"],\n",
    "#         [\"DD_0_1\"],\n",
    "#         [\"DD_1_1\"],\n",
    "#         [\"Dz_0_0_0\"],\n",
    "#         [\"Dz_0_1_1\"],\n",
    "#         [\"Dz_1_1_1\"],\n",
    "#         [\"pi2_0_0_1_1\"],\n",
    "#         [\"pi2_0_1_0_1\"],\n",
    "#         [\"pi2_1_1_1_1\"],\n",
    "#     ],\n",
    "#     labels=[\n",
    "#         [r\"$D_0^2$\"],\n",
    "#         [r\"$D_0 D_1$\"],\n",
    "#         [r\"$D_1^2$\"],\n",
    "#         [r\"$Dz_{0,0,0}$\"],\n",
    "#         [r\"$Dz_{0,1,1}$\"],\n",
    "#         [r\"$Dz_{1,1,1}$\"],\n",
    "#         [r\"$\\pi_{2;0,0,1,1}$\"],\n",
    "#         [r\"$\\pi_{2;0,1,0,1}$\"],\n",
    "#         [r\"$\\pi_{2;1,1,1,1}$\"],\n",
    "#     ],\n",
    "#     rows=3,\n",
    "#     plot_vcs=True,\n",
    "#     show=False,\n",
    "#     fig_size=(6, 4),\n",
    "#     output=\"split_mig_comparison.pdf\",\n",
    "# )\n",
    "\n",
    "print(\"running inference\")\n",
    "# Run inference using the parsed data\n",
    "demo_func = moments.LD.Demographics2D.split_mig\n",
    "# Set up the initial guess\n",
    "# The split_mig function takes four parameters (nu0, nu1, T, m), and we append\n",
    "# the last parameter to fit Ne, which doesn't get passed to the function but\n",
    "# scales recombination rates so can be simultaneously fit\n",
    "p_guess = [0.1, 2, 0.075, 2, 10000]\n",
    "p_guess = moments.LD.Util.perturb_params(p_guess, fold=0.1)\n",
    "opt_params, LL = moments.LD.Inference.optimize_log_lbfgsb(\n",
    "    p_guess, [mv[\"means\"], mv[\"varcovs\"]], [demo_func], rs=r_bins,\n",
    ")\n",
    "\n",
    "physical_units = moments.LD.Util.rescale_params(\n",
    "    opt_params, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"]\n",
    ")\n",
    "\n",
    "print(\"Simulated parameters:\")\n",
    "print(f\"  N(deme0)         :  {g.demes[1].epochs[0].start_size:.1f}\")\n",
    "print(f\"  N(deme1)         :  {g.demes[2].epochs[0].start_size:.1f}\")\n",
    "print(f\"  Div. time (gen)  :  {g.demes[1].epochs[0].start_time:.1f}\")\n",
    "print(f\"  Migration rate   :  {g.migrations[0].rate:.6f}\")\n",
    "print(f\"  N(ancestral)     :  {g.demes[0].epochs[0].start_size:.1f}\")\n",
    "\n",
    "print(\"best fit parameters:\")\n",
    "print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")\n",
    "\n",
    "    # print(\"computing confidence intervals for parameters\")\n",
    "    # uncerts = moments.LD.Godambe.GIM_uncert(\n",
    "    #     demo_func, all_boot, opt_params, mv[\"means\"], mv[\"varcovs\"], r_edges=r_bins,\n",
    "    # )\n",
    "\n",
    "    # lower = opt_params - 1.96 * uncerts\n",
    "    # upper = opt_params + 1.96 * uncerts\n",
    "\n",
    "    # lower_pu = moments.LD.Util.rescale_params(lower, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"])\n",
    "    # upper_pu = moments.LD.Util.rescale_params(upper, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"])\n",
    "\n",
    "    # print(\"95% CIs:\")\n",
    "    # print(f\"  N(deme0)         :  {lower_pu[0]:.1f} - {upper_pu[0]:.1f}\")\n",
    "    # print(f\"  N(deme1)         :  {lower_pu[1]:.1f} - {upper_pu[1]:.1f}\")\n",
    "    # print(f\"  Div. time (gen)  :  {lower_pu[2]:.1f} - {upper_pu[2]:.1f}\")\n",
    "    # print(f\"  Migration rate   :  {lower_pu[3]:.6f} - {upper_pu[3]:.6f}\")\n",
    "    # print(f\"  N(ancestral)     :  {lower_pu[4]:.1f} - {upper_pu[4]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best fit parameters:\")\n",
    "print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import msprime\n",
    "import moments\n",
    "import demes\n",
    "import ray\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './data/*.vcf.gz': No such file or directory\n",
      "rm: cannot remove './data/*.h5': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert msprime.__version__ >= \"1\"\n",
    "\n",
    "if not os.path.isdir(\"./data/\"):\n",
    "    os.makedirs(\"./data/\")\n",
    "os.system(\"rm ./data/*.vcf.gz\")\n",
    "os.system(\"rm ./data/*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound_params = {\n",
    "    \"t_split\": 5000, \n",
    "    \"m\": 1e-4,\n",
    "    \"N1\": 10000,\n",
    "    \"N2\": 10000,\n",
    "    \"Na\": 20000\n",
    "}\n",
    "\n",
    "lower_bound_params =  {\n",
    "    \"t_split\": 100, \n",
    "    \"m\": 1e-8,\n",
    "    \"N1\": 100,\n",
    "    \"N2\": 100,\n",
    "    \"Na\": 10000\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_params():\n",
    "    sampled_params = {}\n",
    "    for key in lower_bound_params:\n",
    "        lower_bound = lower_bound_params[key]\n",
    "        upper_bound = upper_bound_params[key]\n",
    "        sampled_value = np.random.uniform(lower_bound, upper_bound)\n",
    "\n",
    "        # Initialize adjusted_value with sampled_value by default\n",
    "        adjusted_value = sampled_value\n",
    "\n",
    "        # Check if the sampled parameter is equal to the mean of the uniform distribution\n",
    "        mean_value = (lower_bound + upper_bound) / 2\n",
    "        if sampled_value == mean_value:\n",
    "            # Add a small random value to avoid exact mean, while keeping within bounds\n",
    "            adjustment = np.random.uniform(-0.1 * (upper_bound - lower_bound), 0.1 * (upper_bound - lower_bound))\n",
    "            adjusted_value = sampled_value + adjustment\n",
    "            # Ensure the adjusted value is still within the bounds\n",
    "            adjusted_value = max(min(adjusted_value, upper_bound), lower_bound)\n",
    "\n",
    "        # Assign adjusted_value to sampled_params\n",
    "        if key == \"m\":\n",
    "            sampled_params[key] = adjusted_value\n",
    "        else:\n",
    "            sampled_params[key] = int(adjusted_value)\n",
    "\n",
    "    return sampled_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_model(sampled_params):\n",
    "\n",
    "    # Unpack the sampled parameters\n",
    "    Na, N1, N2, m, t_split = (\n",
    "        sampled_params[\"Na\"],  # Effective population size of the ancestral population\n",
    "        sampled_params[\"N1\"],  # Size of population 1 after split\n",
    "        sampled_params[\"N2\"],  # Size of population 2 after split\n",
    "        sampled_params[\"m\"],   # Migration rate between populations\n",
    "        sampled_params[\"t_split\"],  # Time of the population split (in generations)\n",
    "    )\n",
    "\n",
    "    b = demes.Builder()\n",
    "    b.add_deme(\"Na\", epochs=[dict(start_size=Na, end_time=t_split)])\n",
    "    b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=N1)])\n",
    "    b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=N2)])\n",
    "    b.add_migration(demes=[\"N1\", \"N2\"], rate=m)\n",
    "    g = b.resolve()\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_msprime_replicates(sampled_params, experiment_config, num_reps=100, L=1000000, u=1.5e-8, r=1.5e-8):\n",
    "\n",
    "    g = demographic_model(sampled_params)\n",
    "    demog = msprime.Demography.from_demes(g)\n",
    "    tree_sequences = msprime.sim_ancestry(\n",
    "        {\"N1\": experiment_config['num_samples']['N1'], \"N2\": experiment_config['num_samples']['N2']},\n",
    "        demography=demog,\n",
    "        sequence_length=experiment_config['genome_length'],\n",
    "        recombination_rate=experiment_config['recombination_rate'],\n",
    "        num_replicates=experiment_config['num_reps'],\n",
    "        random_seed=experiment_config['seed'],\n",
    "    )\n",
    "    for ii, ts in enumerate(tree_sequences):\n",
    "        ts = msprime.sim_mutations(ts, rate=u, random_seed=ii + 1)\n",
    "        vcf_name = \"./data/split_mig.{0}.vcf\".format(ii)\n",
    "        with open(vcf_name, \"w+\") as fout:\n",
    "            ts.write_vcf(fout, allow_position_zero=True)\n",
    "        os.system(f\"gzip {vcf_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_samples_and_rec_map(experiment_config):\n",
    "\n",
    "    # Define the file paths\n",
    "    samples_file = \"./data/samples.txt\"\n",
    "    flat_map_file =\"./data/flat_map.txt\"\n",
    "\n",
    "    # Open and write the sample file\n",
    "    with open(samples_file, \"w+\") as fout:\n",
    "        fout.write(\"sample\\tpop\\n\")\n",
    "\n",
    "        # Dynamically define samples based on the num_samples dictionary\n",
    "        sample_idx = 0  # Initialize sample index\n",
    "        for pop_name, sample_size in experiment_config['num_samples'].items():\n",
    "            for _ in range(sample_size):\n",
    "                fout.write(f\"tsk_{sample_idx}\\t{pop_name}\\n\")\n",
    "                sample_idx += 1\n",
    "\n",
    "    # Write the recombination map file\n",
    "    with open(flat_map_file, \"w+\") as fout:\n",
    "        fout.write(\"pos\\tMap(cM)\\n\")\n",
    "        fout.write(\"0\\t0\\n\")\n",
    "        fout.write(f\"{experiment_config['genome_length']}\\t{experiment_config['recombination_rate'] * experiment_config['genome_length'] * 100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your function with Ray's remote decorator\n",
    "@ray.remote\n",
    "def get_LD_stats(rep_ii, r_bins):\n",
    "    vcf_file = f\"./data/split_mig.{rep_ii}.vcf.gz\"\n",
    "    time1 = time.time()\n",
    "    ld_stats = moments.LD.Parsing.compute_ld_statistics(\n",
    "        vcf_file,\n",
    "        rec_map_file=\"./data/flat_map.txt\",\n",
    "        pop_file=\"./data/samples.txt\",\n",
    "        pops=[\"N1\", \"N2\"],\n",
    "        r_bins=r_bins,\n",
    "        report=False,\n",
    "    )\n",
    "    time2 = time.time()\n",
    "    print(\"  finished rep\", rep_ii, \"in\", int(time2 - time1), \"seconds\")\n",
    "    return ld_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 10:35:55,246\tINFO worker.py:1614 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running msprime and writing vcfs\n",
      "writing samples and recombination map\n",
      "parsing LD statistics in parallel\n",
      "computing mean and varcov matrix from LD statistics sums\n",
      "computing bootstrap replicates of mean statistics (for confidence intervals\n",
      "running inference\n",
      "Simulated parameters:\n",
      "  N(deme0)         :  199.0\n",
      "  N(deme1)         :  6165.0\n",
      "  Div. time (gen)  :  2755.0\n",
      "  Migration rate   :  0.000070\n",
      "  N(ancestral)     :  18663.0\n",
      "best fit parameters:\n",
      "  N(deme0)         :  1.6\n",
      "  N(deme1)         :  325.8\n",
      "  Div. time (gen)  :  4.5\n",
      "  Migration rate   :  0.008037\n",
      "  N(ancestral)     :  6836.8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_reps = 100\n",
    "    # define the bin edges\n",
    "    r_bins = np.array([0, 1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3])\n",
    "\n",
    "    with open(\"/sietch_colab/akapoor/Demographic_Inference/experiment_config.json\") as f:\n",
    "        experiment_config = json.load(f)\n",
    "\n",
    "\n",
    "    # Initialize Ray\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    # Sample parameters\n",
    "    sampled_params = sample_params()\n",
    "\n",
    "    print(\"running msprime and writing vcfs\")\n",
    "    run_msprime_replicates(sampled_params, experiment_config)\n",
    "    # run_msprime_replicates(experiment_config=experiment_config, num_reps=num_reps)\n",
    "\n",
    "    print(\"writing samples and recombination map\")\n",
    "    write_samples_and_rec_map(experiment_config=experiment_config)\n",
    "\n",
    "    print(\"parsing LD statistics in parallel\")\n",
    "    # Submit tasks to Ray in parallel using .remote()\n",
    "    futures = [get_LD_stats.remote(ii, r_bins) for ii in range(num_reps)]\n",
    "    # Gather results with ray.get() to collect them once the tasks are finished\n",
    "    ld_stats = ray.get(futures)\n",
    "    # Optionally, you can convert the list of results into a dictionary with indices\n",
    "    ld_stats_dict = {ii: result for ii, result in enumerate(ld_stats)}\n",
    "\n",
    "    print(\"computing mean and varcov matrix from LD statistics sums\")\n",
    "    mv = moments.LD.Parsing.bootstrap_data(ld_stats_dict)\n",
    "    with open(f\"./data/means.varcovs.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(mv, fout)\n",
    "    print(\n",
    "        \"computing bootstrap replicates of mean statistics (for confidence intervals\"\n",
    "    )\n",
    "    all_boot = moments.LD.Parsing.get_bootstrap_sets(ld_stats_dict)\n",
    "    with open(f\"./data/bootstrap_sets.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(all_boot, fout)\n",
    "    os.system(\"rm ./data/*.vcf.gz\")\n",
    "    os.system(\"rm ./data/*.h5\")\n",
    "\n",
    "    g = demographic_model(sampled_params)\n",
    "\n",
    "    print(\"running inference\")\n",
    "    # Run inference using the parsed data\n",
    "    demo_func = moments.LD.Demographics2D.split_mig\n",
    "    # Set up the initial guess\n",
    "    # The split_mig function takes four parameters (nu0, nu1, T, m), and we append\n",
    "    # the last parameter to fit Ne, which doesn't get passed to the function but\n",
    "    # scales recombination rates so can be simultaneously fit\n",
    "    p_guess = [0.1, 2, 0.075, 2, 10000]\n",
    "    p_guess = moments.LD.Util.perturb_params(p_guess, fold=0.1)\n",
    "    opt_params, LL = moments.LD.Inference.optimize_log_lbfgsb(\n",
    "        p_guess, [mv[\"means\"], mv[\"varcovs\"]], [demo_func], rs=r_bins,\n",
    "    )\n",
    "\n",
    "    physical_units = moments.LD.Util.rescale_params(\n",
    "        opt_params, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"]\n",
    "    )\n",
    "\n",
    "    print(\"Simulated parameters:\")\n",
    "    print(f\"  N(deme0)         :  {g.demes[1].epochs[0].start_size:.1f}\")\n",
    "    print(f\"  N(deme1)         :  {g.demes[2].epochs[0].start_size:.1f}\")\n",
    "    print(f\"  Div. time (gen)  :  {g.demes[1].epochs[0].start_time:.1f}\")\n",
    "    print(f\"  Migration rate   :  {g.migrations[0].rate:.6f}\")\n",
    "    print(f\"  N(ancestral)     :  {g.demes[0].epochs[0].start_size:.1f}\")\n",
    "\n",
    "    print(\"best fit parameters:\")\n",
    "    print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "    print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "    print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "    print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "    print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/sietch_colab/akapoor/Demographic_Inference/split_isolation_model_seed_42/sims/sims_pretrain_2_sims_inference_1_seed_42_num_replicates_10_top_values_5/simulation_results/software_inferences_sim_0.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_split': 4398, 'N1': 6647, 'N2': 8609, 'Na': 944, 'm': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['simulated_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N1': 9630.4847057122,\n",
       " 'N2': 11112.656100956929,\n",
       " 't_split': 2880.544777334798,\n",
       " 'm': 2.3887289546488923e-09,\n",
       " 'Na': 305.67757773500995}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['opt_params_momentsLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('/sietch_colab/akapoor/Demographic_Inference/split_isolation_model_dadi_analysis_True_moments_analysis_True_momentsLD_analysis_True_seed_42/sims/sims_pretrain_20_sims_inference_1_seed_42_num_replicates_3_top_values_2/preprocessing_results_obj.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moments_rep1_Na</th>\n",
       "      <th>Moments_rep1_N1</th>\n",
       "      <th>Moments_rep1_N2</th>\n",
       "      <th>Moments_rep1_t_split</th>\n",
       "      <th>Moments_rep1_m</th>\n",
       "      <th>Moments_rep1_FIM_element_0</th>\n",
       "      <th>Moments_rep1_FIM_element_1</th>\n",
       "      <th>Moments_rep1_FIM_element_2</th>\n",
       "      <th>Moments_rep1_FIM_element_3</th>\n",
       "      <th>Moments_rep1_FIM_element_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Dadi_rep2_Na</th>\n",
       "      <th>Dadi_rep2_N1</th>\n",
       "      <th>Dadi_rep2_N2</th>\n",
       "      <th>Dadi_rep2_t_split</th>\n",
       "      <th>Dadi_rep2_m</th>\n",
       "      <th>MomentsLD_N1</th>\n",
       "      <th>MomentsLD_N2</th>\n",
       "      <th>MomentsLD_t_split</th>\n",
       "      <th>MomentsLD_m</th>\n",
       "      <th>MomentsLD_Na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sim_0</th>\n",
       "      <td>21112.439485</td>\n",
       "      <td>159.833039</td>\n",
       "      <td>9385.387931</td>\n",
       "      <td>5771.687435</td>\n",
       "      <td>4112.281243</td>\n",
       "      <td>-4.907393e+09</td>\n",
       "      <td>-1.383656e+05</td>\n",
       "      <td>2.249975e+05</td>\n",
       "      <td>-1.263158e+06</td>\n",
       "      <td>-942545.891755</td>\n",
       "      <td>...</td>\n",
       "      <td>14793.417999</td>\n",
       "      <td>258.950678</td>\n",
       "      <td>7299.776576</td>\n",
       "      <td>2.958684</td>\n",
       "      <td>1101.575686</td>\n",
       "      <td>7038.050741</td>\n",
       "      <td>6819.277799</td>\n",
       "      <td>1761.031508</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>15197.338220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_1</th>\n",
       "      <td>14893.308305</td>\n",
       "      <td>206.801364</td>\n",
       "      <td>7483.830946</td>\n",
       "      <td>2467.643413</td>\n",
       "      <td>902.426049</td>\n",
       "      <td>-3.055176e+09</td>\n",
       "      <td>2.168995e+05</td>\n",
       "      <td>-1.796326e+08</td>\n",
       "      <td>-2.637244e+08</td>\n",
       "      <td>-84832.524027</td>\n",
       "      <td>...</td>\n",
       "      <td>13198.095118</td>\n",
       "      <td>245.393432</td>\n",
       "      <td>9870.830102</td>\n",
       "      <td>889.903707</td>\n",
       "      <td>2332.296159</td>\n",
       "      <td>3678.049535</td>\n",
       "      <td>1532.624299</td>\n",
       "      <td>1693.330257</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>15270.522749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_2</th>\n",
       "      <td>17299.832158</td>\n",
       "      <td>93.819223</td>\n",
       "      <td>7926.575644</td>\n",
       "      <td>1378.614725</td>\n",
       "      <td>2344.053820</td>\n",
       "      <td>1.728992e+10</td>\n",
       "      <td>2.811045e+06</td>\n",
       "      <td>-7.628733e+09</td>\n",
       "      <td>-8.327025e+08</td>\n",
       "      <td>-403695.663927</td>\n",
       "      <td>...</td>\n",
       "      <td>13429.085536</td>\n",
       "      <td>112.961293</td>\n",
       "      <td>21149.861019</td>\n",
       "      <td>2.685817</td>\n",
       "      <td>1410.580881</td>\n",
       "      <td>5423.988086</td>\n",
       "      <td>7337.471393</td>\n",
       "      <td>299.603545</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>14462.701681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_3</th>\n",
       "      <td>18314.590698</td>\n",
       "      <td>119.627274</td>\n",
       "      <td>16784.302903</td>\n",
       "      <td>2122.992550</td>\n",
       "      <td>1048.935903</td>\n",
       "      <td>1.877295e+10</td>\n",
       "      <td>6.612261e+05</td>\n",
       "      <td>-4.227615e+09</td>\n",
       "      <td>-1.153892e+09</td>\n",
       "      <td>-56553.322367</td>\n",
       "      <td>...</td>\n",
       "      <td>15441.880022</td>\n",
       "      <td>206.305236</td>\n",
       "      <td>12660.736028</td>\n",
       "      <td>3.088376</td>\n",
       "      <td>2041.474113</td>\n",
       "      <td>9504.116260</td>\n",
       "      <td>8699.632792</td>\n",
       "      <td>3538.050891</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>15140.103630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_4</th>\n",
       "      <td>17247.124364</td>\n",
       "      <td>140.268207</td>\n",
       "      <td>9411.153296</td>\n",
       "      <td>1408.819922</td>\n",
       "      <td>1002.796158</td>\n",
       "      <td>-1.633327e+10</td>\n",
       "      <td>-9.968390e+05</td>\n",
       "      <td>1.012877e+09</td>\n",
       "      <td>-1.743030e+08</td>\n",
       "      <td>-243973.371336</td>\n",
       "      <td>...</td>\n",
       "      <td>16378.200267</td>\n",
       "      <td>114.393964</td>\n",
       "      <td>6636.159229</td>\n",
       "      <td>323.054448</td>\n",
       "      <td>1878.296990</td>\n",
       "      <td>5505.918547</td>\n",
       "      <td>10150.189089</td>\n",
       "      <td>3376.142390</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>13050.977744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_5</th>\n",
       "      <td>19067.070138</td>\n",
       "      <td>148.210334</td>\n",
       "      <td>26212.131849</td>\n",
       "      <td>2715.285980</td>\n",
       "      <td>997.936631</td>\n",
       "      <td>2.265836e+10</td>\n",
       "      <td>9.804823e+05</td>\n",
       "      <td>-4.407385e+09</td>\n",
       "      <td>-1.525762e+09</td>\n",
       "      <td>-29567.501059</td>\n",
       "      <td>...</td>\n",
       "      <td>16964.211959</td>\n",
       "      <td>244.781437</td>\n",
       "      <td>22018.619059</td>\n",
       "      <td>3.392842</td>\n",
       "      <td>2693.690151</td>\n",
       "      <td>35.359778</td>\n",
       "      <td>26.079385</td>\n",
       "      <td>1.095955</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>19426.230490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_6</th>\n",
       "      <td>15580.919976</td>\n",
       "      <td>220.899263</td>\n",
       "      <td>12524.524319</td>\n",
       "      <td>1945.504280</td>\n",
       "      <td>779.606914</td>\n",
       "      <td>-5.921458e+09</td>\n",
       "      <td>-6.129035e+05</td>\n",
       "      <td>4.571720e+08</td>\n",
       "      <td>-9.255619e+07</td>\n",
       "      <td>-28826.627694</td>\n",
       "      <td>...</td>\n",
       "      <td>15337.390456</td>\n",
       "      <td>152.324784</td>\n",
       "      <td>8463.419293</td>\n",
       "      <td>408.223632</td>\n",
       "      <td>1321.054388</td>\n",
       "      <td>5828.168517</td>\n",
       "      <td>2521.989184</td>\n",
       "      <td>1993.555848</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>15932.713201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_7</th>\n",
       "      <td>14745.342069</td>\n",
       "      <td>76.432879</td>\n",
       "      <td>8755.957360</td>\n",
       "      <td>2922.506387</td>\n",
       "      <td>979.935560</td>\n",
       "      <td>-5.251242e+09</td>\n",
       "      <td>3.782126e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-335433.380523</td>\n",
       "      <td>...</td>\n",
       "      <td>13246.518258</td>\n",
       "      <td>229.825593</td>\n",
       "      <td>7022.120561</td>\n",
       "      <td>334.967993</td>\n",
       "      <td>1994.462224</td>\n",
       "      <td>2293.501704</td>\n",
       "      <td>9089.698203</td>\n",
       "      <td>2399.750794</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>12064.679844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_8</th>\n",
       "      <td>23155.467015</td>\n",
       "      <td>136.693765</td>\n",
       "      <td>11710.013030</td>\n",
       "      <td>4916.543875</td>\n",
       "      <td>3635.141128</td>\n",
       "      <td>-7.375966e+09</td>\n",
       "      <td>-2.339712e+05</td>\n",
       "      <td>-7.430167e+05</td>\n",
       "      <td>-1.507400e+06</td>\n",
       "      <td>-586297.899949</td>\n",
       "      <td>...</td>\n",
       "      <td>20268.189670</td>\n",
       "      <td>333.767280</td>\n",
       "      <td>10208.050711</td>\n",
       "      <td>679.283155</td>\n",
       "      <td>1173.498749</td>\n",
       "      <td>4481.245760</td>\n",
       "      <td>7829.912082</td>\n",
       "      <td>4231.195936</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>20650.946412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sim_9</th>\n",
       "      <td>12131.799863</td>\n",
       "      <td>88.532501</td>\n",
       "      <td>13128.454184</td>\n",
       "      <td>1137.617629</td>\n",
       "      <td>732.196212</td>\n",
       "      <td>-8.341872e+09</td>\n",
       "      <td>-2.800902e+05</td>\n",
       "      <td>-3.885596e+08</td>\n",
       "      <td>-3.367440e+08</td>\n",
       "      <td>-9145.790713</td>\n",
       "      <td>...</td>\n",
       "      <td>11744.060260</td>\n",
       "      <td>210.280118</td>\n",
       "      <td>9411.527620</td>\n",
       "      <td>225.403146</td>\n",
       "      <td>1229.296066</td>\n",
       "      <td>4572.561258</td>\n",
       "      <td>4280.818480</td>\n",
       "      <td>4019.742504</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>12163.705507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Moments_rep1_Na  Moments_rep1_N1  Moments_rep1_N2  \\\n",
       "Sim_0     21112.439485       159.833039      9385.387931   \n",
       "Sim_1     14893.308305       206.801364      7483.830946   \n",
       "Sim_2     17299.832158        93.819223      7926.575644   \n",
       "Sim_3     18314.590698       119.627274     16784.302903   \n",
       "Sim_4     17247.124364       140.268207      9411.153296   \n",
       "Sim_5     19067.070138       148.210334     26212.131849   \n",
       "Sim_6     15580.919976       220.899263     12524.524319   \n",
       "Sim_7     14745.342069        76.432879      8755.957360   \n",
       "Sim_8     23155.467015       136.693765     11710.013030   \n",
       "Sim_9     12131.799863        88.532501     13128.454184   \n",
       "\n",
       "       Moments_rep1_t_split  Moments_rep1_m  Moments_rep1_FIM_element_0  \\\n",
       "Sim_0           5771.687435     4112.281243               -4.907393e+09   \n",
       "Sim_1           2467.643413      902.426049               -3.055176e+09   \n",
       "Sim_2           1378.614725     2344.053820                1.728992e+10   \n",
       "Sim_3           2122.992550     1048.935903                1.877295e+10   \n",
       "Sim_4           1408.819922     1002.796158               -1.633327e+10   \n",
       "Sim_5           2715.285980      997.936631                2.265836e+10   \n",
       "Sim_6           1945.504280      779.606914               -5.921458e+09   \n",
       "Sim_7           2922.506387      979.935560               -5.251242e+09   \n",
       "Sim_8           4916.543875     3635.141128               -7.375966e+09   \n",
       "Sim_9           1137.617629      732.196212               -8.341872e+09   \n",
       "\n",
       "       Moments_rep1_FIM_element_1  Moments_rep1_FIM_element_2  \\\n",
       "Sim_0               -1.383656e+05                2.249975e+05   \n",
       "Sim_1                2.168995e+05               -1.796326e+08   \n",
       "Sim_2                2.811045e+06               -7.628733e+09   \n",
       "Sim_3                6.612261e+05               -4.227615e+09   \n",
       "Sim_4               -9.968390e+05                1.012877e+09   \n",
       "Sim_5                9.804823e+05               -4.407385e+09   \n",
       "Sim_6               -6.129035e+05                4.571720e+08   \n",
       "Sim_7                3.782126e+04                0.000000e+00   \n",
       "Sim_8               -2.339712e+05               -7.430167e+05   \n",
       "Sim_9               -2.800902e+05               -3.885596e+08   \n",
       "\n",
       "       Moments_rep1_FIM_element_3  Moments_rep1_FIM_element_4  ...  \\\n",
       "Sim_0               -1.263158e+06              -942545.891755  ...   \n",
       "Sim_1               -2.637244e+08               -84832.524027  ...   \n",
       "Sim_2               -8.327025e+08              -403695.663927  ...   \n",
       "Sim_3               -1.153892e+09               -56553.322367  ...   \n",
       "Sim_4               -1.743030e+08              -243973.371336  ...   \n",
       "Sim_5               -1.525762e+09               -29567.501059  ...   \n",
       "Sim_6               -9.255619e+07               -28826.627694  ...   \n",
       "Sim_7                0.000000e+00              -335433.380523  ...   \n",
       "Sim_8               -1.507400e+06              -586297.899949  ...   \n",
       "Sim_9               -3.367440e+08                -9145.790713  ...   \n",
       "\n",
       "       Dadi_rep2_Na  Dadi_rep2_N1  Dadi_rep2_N2  Dadi_rep2_t_split  \\\n",
       "Sim_0  14793.417999    258.950678   7299.776576           2.958684   \n",
       "Sim_1  13198.095118    245.393432   9870.830102         889.903707   \n",
       "Sim_2  13429.085536    112.961293  21149.861019           2.685817   \n",
       "Sim_3  15441.880022    206.305236  12660.736028           3.088376   \n",
       "Sim_4  16378.200267    114.393964   6636.159229         323.054448   \n",
       "Sim_5  16964.211959    244.781437  22018.619059           3.392842   \n",
       "Sim_6  15337.390456    152.324784   8463.419293         408.223632   \n",
       "Sim_7  13246.518258    229.825593   7022.120561         334.967993   \n",
       "Sim_8  20268.189670    333.767280  10208.050711         679.283155   \n",
       "Sim_9  11744.060260    210.280118   9411.527620         225.403146   \n",
       "\n",
       "       Dadi_rep2_m  MomentsLD_N1  MomentsLD_N2  MomentsLD_t_split  \\\n",
       "Sim_0  1101.575686   7038.050741   6819.277799        1761.031508   \n",
       "Sim_1  2332.296159   3678.049535   1532.624299        1693.330257   \n",
       "Sim_2  1410.580881   5423.988086   7337.471393         299.603545   \n",
       "Sim_3  2041.474113   9504.116260   8699.632792        3538.050891   \n",
       "Sim_4  1878.296990   5505.918547  10150.189089        3376.142390   \n",
       "Sim_5  2693.690151     35.359778     26.079385           1.095955   \n",
       "Sim_6  1321.054388   5828.168517   2521.989184        1993.555848   \n",
       "Sim_7  1994.462224   2293.501704   9089.698203        2399.750794   \n",
       "Sim_8  1173.498749   4481.245760   7829.912082        4231.195936   \n",
       "Sim_9  1229.296066   4572.561258   4280.818480        4019.742504   \n",
       "\n",
       "       MomentsLD_m  MomentsLD_Na  \n",
       "Sim_0     0.000002  15197.338220  \n",
       "Sim_1     0.000002  15270.522749  \n",
       "Sim_2     0.000002  14462.701681  \n",
       "Sim_3     0.000002  15140.103630  \n",
       "Sim_4     0.000002  13050.977744  \n",
       "Sim_5     0.000002  19426.230490  \n",
       "Sim_6     0.000002  15932.713201  \n",
       "Sim_7     0.000002  12064.679844  \n",
       "Sim_8     0.000002  20650.946412  \n",
       "Sim_9     0.000002  12163.705507  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['training']['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
