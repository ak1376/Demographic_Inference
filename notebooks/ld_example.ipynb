{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './data/*.vcf.gz': No such file or directory\n",
      "rm: cannot remove './data/*.h5': No such file or directory\n",
      "2024-10-15 12:18:31,039\tINFO worker.py:1781 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running msprime and writing vcfs\n",
      "writing samples and recombination map\n",
      "parsing LD statistics in parallel\n",
      "\u001b[36m(get_LD_stats pid=2616889)\u001b[0m   finished rep 99 in 62 seconds\n",
      "\u001b[36m(get_LD_stats pid=2621507)\u001b[0m   finished rep 13 in 68 seconds\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2621185)\u001b[0m   finished rep 70 in 73 seconds\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2622031)\u001b[0m   finished rep 3 in 79 seconds\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(get_LD_stats pid=2621740)\u001b[0m   finished rep 23 in 84 seconds\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "computing mean and varcov matrix from LD statistics sums\n",
      "computing bootstrap replicates of mean statistics (for confidence intervals\n",
      "running inference\n",
      "Simulated parameters:\n",
      "  N(deme0)         :  5064.0\n",
      "  N(deme1)         :  9466.0\n",
      "  Div. time (gen)  :  3431.0\n",
      "  Migration rate   :  0.000056\n",
      "  N(ancestral)     :  11905.0\n",
      "best fit parameters:\n",
      "  N(deme0)         :  5398.0\n",
      "  N(deme1)         :  10047.5\n",
      "  Div. time (gen)  :  3786.1\n",
      "  Migration rate   :  0.000059\n",
      "  N(ancestral)     :  11209.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script uses msprime to simulate under an isolation with migration model,\n",
    "writing the outputs to VCF. We'll simulate a small dataset: 100 x 1Mb regions,\n",
    "each with recombination and mutation rates of 1.5e-8. We'll then use moments\n",
    "to compute LD statistics from each of the 100 replicates to compute statistic\n",
    "means and variances/covariances. These are then used to refit the simulated\n",
    "model using moments.LD, and then we use bootstrapped datasets to estimate\n",
    "confidence intervals.\n",
    "\n",
    "The demographic model is a population of size 10,000 that splits into a\n",
    "population of size 2,000 and a population of size 20,000. The split occurs\n",
    "1,500 generations ago followed by symmetric migration at rate 1e-4.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import msprime\n",
    "import moments\n",
    "import demes\n",
    "import ray\n",
    "import json\n",
    "\n",
    "assert msprime.__version__ >= \"1\"\n",
    "\n",
    "if not os.path.isdir(\"./data/\"):\n",
    "    os.makedirs(\"./data/\")\n",
    "os.system(\"rm ./data/*.vcf.gz\")\n",
    "os.system(\"rm ./data/*.h5\")\n",
    "\n",
    "upper_bound_params = {\n",
    "    \"t_split\": 5000, \n",
    "    \"m\": 1e-4,\n",
    "    \"N1\": 10000,\n",
    "    \"N2\": 10000,\n",
    "    \"Na\": 20000\n",
    "}\n",
    "\n",
    "lower_bound_params =  {\n",
    "    \"t_split\": 100, \n",
    "    \"m\": 1e-8,\n",
    "    \"N1\": 100,\n",
    "    \"N2\": 100,\n",
    "    \"Na\": 10000\n",
    "\n",
    "}\n",
    "\n",
    "def sample_params():\n",
    "    sampled_params = {}\n",
    "    for key in lower_bound_params:\n",
    "        lower_bound = lower_bound_params[key]\n",
    "        upper_bound = upper_bound_params[key]\n",
    "        sampled_value = np.random.uniform(lower_bound, upper_bound)\n",
    "\n",
    "        # Initialize adjusted_value with sampled_value by default\n",
    "        adjusted_value = sampled_value\n",
    "\n",
    "        # Check if the sampled parameter is equal to the mean of the uniform distribution\n",
    "        mean_value = (lower_bound + upper_bound) / 2\n",
    "        if sampled_value == mean_value:\n",
    "            # Add a small random value to avoid exact mean, while keeping within bounds\n",
    "            adjustment = np.random.uniform(-0.1 * (upper_bound - lower_bound), 0.1 * (upper_bound - lower_bound))\n",
    "            adjusted_value = sampled_value + adjustment\n",
    "            # Ensure the adjusted value is still within the bounds\n",
    "            adjusted_value = max(min(adjusted_value, upper_bound), lower_bound)\n",
    "\n",
    "        # Assign adjusted_value to sampled_params\n",
    "        if key == \"m\":\n",
    "            sampled_params[key] = adjusted_value\n",
    "        else:\n",
    "            sampled_params[key] = int(adjusted_value)\n",
    "\n",
    "    return sampled_params\n",
    "\n",
    "def demographic_model(sampled_params):\n",
    "\n",
    "    # Unpack the sampled parameters\n",
    "    Na, N1, N2, m, t_split = (\n",
    "        sampled_params[\"Na\"],  # Effective population size of the ancestral population\n",
    "        sampled_params[\"N1\"],  # Size of population 1 after split\n",
    "        sampled_params[\"N2\"],  # Size of population 2 after split\n",
    "        sampled_params[\"m\"],   # Migration rate between populations\n",
    "        sampled_params[\"t_split\"],  # Time of the population split (in generations)\n",
    "    )\n",
    "\n",
    "    b = demes.Builder()\n",
    "    b.add_deme(\"Na\", epochs=[dict(start_size=Na, end_time=t_split)])\n",
    "    b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=N1)])\n",
    "    b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=N2)])\n",
    "    b.add_migration(demes=[\"N1\", \"N2\"], rate=m)\n",
    "    g = b.resolve()\n",
    "    return g\n",
    "\n",
    "# def demographic_model():\n",
    "#     b = demes.Builder()\n",
    "#     b.add_deme(\"Na\", epochs=[dict(start_size=18575, end_time=1408)])\n",
    "#     b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=617)])\n",
    "#     b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=4559)])\n",
    "#     b.add_migration(demes=[\"N1\", \"N2\"], rate=7.701758925243914e-05)\n",
    "#     g = b.resolve()\n",
    "#     return g\n",
    "\n",
    "# def run_msprime_replicates(experiment_config, num_reps=100):\n",
    "#     # Set up the demography from demes\n",
    "#     g = demographic_model()\n",
    "#     demog = msprime.Demography.from_demes(g)\n",
    "\n",
    "#     # Dynamically define the samples using msprime.SampleSet, based on the sample_sizes dictionary\n",
    "#     samples = [\n",
    "#         msprime.SampleSet(sample_size, population=pop_name, ploidy=1)\n",
    "#         for pop_name, sample_size in experiment_config['num_samples'].items()\n",
    "#     ]\n",
    "\n",
    "#     tree_sequences = msprime.sim_ancestry(\n",
    "#         samples,\n",
    "#         demography=demog,\n",
    "#         sequence_length=experiment_config['genome_length'],\n",
    "#         recombination_rate=experiment_config['recombination_rate'],\n",
    "#         num_replicates=num_reps,\n",
    "#         random_seed=42,\n",
    "#     )\n",
    "#     for ii, ts in enumerate(tree_sequences):\n",
    "#         ts = msprime.sim_mutations(ts, rate=experiment_config['mutation_rate'], random_seed=ii + 1)\n",
    "#         vcf_name = \"./data/split_mig.{0}.vcf\".format(ii)\n",
    "#         with open(vcf_name, \"w+\") as fout:\n",
    "#             ts.write_vcf(fout, allow_position_zero=True)\n",
    "#         os.system(f\"gzip {vcf_name}\")\n",
    "\n",
    "\n",
    "\n",
    "def run_msprime_replicates(sampled_params, experiment_config, u=1.5e-8):\n",
    "\n",
    "    g = demographic_model(sampled_params)\n",
    "    demog = msprime.Demography.from_demes(g)\n",
    "    tree_sequences = msprime.sim_ancestry(\n",
    "        {\"N1\": experiment_config['num_samples']['N1'], \"N2\": experiment_config['num_samples']['N2']},\n",
    "        demography=demog,\n",
    "        sequence_length=experiment_config['genome_length'],\n",
    "        recombination_rate=experiment_config['recombination_rate'],\n",
    "        num_replicates=experiment_config['num_reps'],\n",
    "        random_seed=experiment_config['seed'],\n",
    "    )\n",
    "    for ii, ts in enumerate(tree_sequences):\n",
    "        ts = msprime.sim_mutations(ts, rate=experiment_config['mutation_rate'], random_seed=ii + 1)\n",
    "        vcf_name = \"./data/split_mig.{0}.vcf\".format(ii)\n",
    "        with open(vcf_name, \"w+\") as fout:\n",
    "            ts.write_vcf(fout, allow_position_zero=True)\n",
    "        os.system(f\"gzip {vcf_name}\")\n",
    "\n",
    "def write_samples_and_rec_map(experiment_config):\n",
    "\n",
    "    # Define the file paths\n",
    "    samples_file = \"./data/samples.txt\"\n",
    "    flat_map_file =\"./data/flat_map.txt\"\n",
    "\n",
    "    # Open and write the sample file\n",
    "    with open(samples_file, \"w+\") as fout:\n",
    "        fout.write(\"sample\\tpop\\n\")\n",
    "\n",
    "        # Dynamically define samples based on the num_samples dictionary\n",
    "        sample_idx = 0  # Initialize sample index\n",
    "        for pop_name, sample_size in experiment_config['num_samples'].items():\n",
    "            for _ in range(sample_size):\n",
    "                fout.write(f\"tsk_{sample_idx}\\t{pop_name}\\n\")\n",
    "                sample_idx += 1\n",
    "\n",
    "    # Write the recombination map file\n",
    "    with open(flat_map_file, \"w+\") as fout:\n",
    "        fout.write(\"pos\\tMap(cM)\\n\")\n",
    "        fout.write(\"0\\t0\\n\")\n",
    "        fout.write(f\"{experiment_config['genome_length']}\\t{experiment_config['recombination_rate'] * experiment_config['genome_length'] * 100}\\n\")\n",
    "\n",
    "# def write_samples_and_rec_map(L=1000000, r=1.5e-8, n=18):\n",
    "#     # samples file\n",
    "#     with open(\"./data/samples.txt\", \"w+\") as fout:\n",
    "#         fout.write(\"sample\\tpop\\n\")\n",
    "#         for jj in range(2):\n",
    "#             for ii in range(n):\n",
    "#                 fout.write(f\"tsk_{jj * n + ii}\\tdeme{jj}\\n\")\n",
    "#     # recombination map\n",
    "#     with open(\"./data/flat_map.txt\", \"w+\") as fout:\n",
    "#         fout.write(\"pos\\tMap(cM)\\n\")\n",
    "#         fout.write(\"0\\t0\\n\")\n",
    "#         fout.write(f\"{L}\\t{r * L * 100}\\n\")\n",
    "\n",
    "# Define your function with Ray's remote decorator\n",
    "@ray.remote\n",
    "def get_LD_stats(rep_ii, r_bins):\n",
    "    vcf_file = f\"./data/split_mig.{rep_ii}.vcf.gz\"\n",
    "    time1 = time.time()\n",
    "    ld_stats = moments.LD.Parsing.compute_ld_statistics(\n",
    "        vcf_file,\n",
    "        rec_map_file=\"./data/flat_map.txt\",\n",
    "        pop_file=\"./data/samples.txt\",\n",
    "        pops=[\"N1\", \"N2\"],\n",
    "        r_bins=r_bins,\n",
    "        report=False,\n",
    "    )\n",
    "    time2 = time.time()\n",
    "    print(\"  finished rep\", rep_ii, \"in\", int(time2 - time1), \"seconds\")\n",
    "    return ld_stats\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_reps = 100\n",
    "    # define the bin edges\n",
    "    r_bins = np.array([0, 1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3])\n",
    "\n",
    "    with open(\"/sietch_colab/akapoor/Demographic_Inference/experiment_config.json\") as f:\n",
    "        experiment_config = json.load(f)\n",
    "\n",
    "\n",
    "    # Initialize Ray\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    # Sample parameters\n",
    "    sampled_params = sample_params()\n",
    "\n",
    "    print(\"running msprime and writing vcfs\")\n",
    "    run_msprime_replicates(sampled_params, experiment_config)\n",
    "    # run_msprime_replicates(experiment_config=experiment_config, num_reps=num_reps)\n",
    "\n",
    "    print(\"writing samples and recombination map\")\n",
    "    write_samples_and_rec_map(experiment_config=experiment_config)\n",
    "\n",
    "    print(\"parsing LD statistics in parallel\")\n",
    "    # Submit tasks to Ray in parallel using .remote()\n",
    "    futures = [get_LD_stats.remote(ii, r_bins) for ii in range(num_reps)]\n",
    "    # Gather results with ray.get() to collect them once the tasks are finished\n",
    "    ld_stats = ray.get(futures)\n",
    "    # Optionally, you can convert the list of results into a dictionary with indices\n",
    "    ld_stats_dict = {ii: result for ii, result in enumerate(ld_stats)}\n",
    "\n",
    "    print(\"computing mean and varcov matrix from LD statistics sums\")\n",
    "    mv = moments.LD.Parsing.bootstrap_data(ld_stats_dict)\n",
    "    with open(f\"./data/means.varcovs.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(mv, fout)\n",
    "    print(\n",
    "        \"computing bootstrap replicates of mean statistics (for confidence intervals\"\n",
    "    )\n",
    "    all_boot = moments.LD.Parsing.get_bootstrap_sets(ld_stats_dict)\n",
    "    with open(f\"./data/bootstrap_sets.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(all_boot, fout)\n",
    "    os.system(\"rm ./data/*.vcf.gz\")\n",
    "    os.system(\"rm ./data/*.h5\")\n",
    "\n",
    "# print(\"computing expectations under the model\")\n",
    "g = demographic_model(sampled_params)\n",
    "# y = moments.Demes.LD(g, sampled_demes=[\"deme0\", \"deme1\"], rho=4 * 10000 * r_bins)\n",
    "# y = moments.LD.LDstats(\n",
    "#     [(y_l + y_r) / 2 for y_l, y_r in zip(y[:-2], y[1:-1])] + [y[-1]],\n",
    "#     num_pops=y.num_pops,\n",
    "#     pop_ids=y.pop_ids,\n",
    "# )\n",
    "# y = moments.LD.Inference.sigmaD2(y)\n",
    "\n",
    "# plot simulated data vs expectations under the model\n",
    "# fig = moments.LD.Plotting.plot_ld_curves_comp(\n",
    "#     y,\n",
    "#     mv[\"means\"][:-1],\n",
    "#     mv[\"varcovs\"][:-1],\n",
    "#     rs=r_bins,\n",
    "#     stats_to_plot=[\n",
    "#         [\"DD_0_0\"],\n",
    "#         [\"DD_0_1\"],\n",
    "#         [\"DD_1_1\"],\n",
    "#         [\"Dz_0_0_0\"],\n",
    "#         [\"Dz_0_1_1\"],\n",
    "#         [\"Dz_1_1_1\"],\n",
    "#         [\"pi2_0_0_1_1\"],\n",
    "#         [\"pi2_0_1_0_1\"],\n",
    "#         [\"pi2_1_1_1_1\"],\n",
    "#     ],\n",
    "#     labels=[\n",
    "#         [r\"$D_0^2$\"],\n",
    "#         [r\"$D_0 D_1$\"],\n",
    "#         [r\"$D_1^2$\"],\n",
    "#         [r\"$Dz_{0,0,0}$\"],\n",
    "#         [r\"$Dz_{0,1,1}$\"],\n",
    "#         [r\"$Dz_{1,1,1}$\"],\n",
    "#         [r\"$\\pi_{2;0,0,1,1}$\"],\n",
    "#         [r\"$\\pi_{2;0,1,0,1}$\"],\n",
    "#         [r\"$\\pi_{2;1,1,1,1}$\"],\n",
    "#     ],\n",
    "#     rows=3,\n",
    "#     plot_vcs=True,\n",
    "#     show=False,\n",
    "#     fig_size=(6, 4),\n",
    "#     output=\"split_mig_comparison.pdf\",\n",
    "# )\n",
    "\n",
    "print(\"running inference\")\n",
    "# Run inference using the parsed data\n",
    "demo_func = moments.LD.Demographics2D.split_mig\n",
    "# Set up the initial guess\n",
    "# The split_mig function takes four parameters (nu0, nu1, T, m), and we append\n",
    "# the last parameter to fit Ne, which doesn't get passed to the function but\n",
    "# scales recombination rates so can be simultaneously fit\n",
    "p_guess = [0.1, 2, 0.075, 2, 10000]\n",
    "p_guess = moments.LD.Util.perturb_params(p_guess, fold=0.1)\n",
    "opt_params, LL = moments.LD.Inference.optimize_log_lbfgsb(\n",
    "    p_guess, [mv[\"means\"], mv[\"varcovs\"]], [demo_func], rs=r_bins,\n",
    ")\n",
    "\n",
    "physical_units = moments.LD.Util.rescale_params(\n",
    "    opt_params, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"]\n",
    ")\n",
    "\n",
    "print(\"Simulated parameters:\")\n",
    "print(f\"  N(deme0)         :  {g.demes[1].epochs[0].start_size:.1f}\")\n",
    "print(f\"  N(deme1)         :  {g.demes[2].epochs[0].start_size:.1f}\")\n",
    "print(f\"  Div. time (gen)  :  {g.demes[1].epochs[0].start_time:.1f}\")\n",
    "print(f\"  Migration rate   :  {g.migrations[0].rate:.6f}\")\n",
    "print(f\"  N(ancestral)     :  {g.demes[0].epochs[0].start_size:.1f}\")\n",
    "\n",
    "print(\"best fit parameters:\")\n",
    "print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")\n",
    "\n",
    "    # print(\"computing confidence intervals for parameters\")\n",
    "    # uncerts = moments.LD.Godambe.GIM_uncert(\n",
    "    #     demo_func, all_boot, opt_params, mv[\"means\"], mv[\"varcovs\"], r_edges=r_bins,\n",
    "    # )\n",
    "\n",
    "    # lower = opt_params - 1.96 * uncerts\n",
    "    # upper = opt_params + 1.96 * uncerts\n",
    "\n",
    "    # lower_pu = moments.LD.Util.rescale_params(lower, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"])\n",
    "    # upper_pu = moments.LD.Util.rescale_params(upper, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"])\n",
    "\n",
    "    # print(\"95% CIs:\")\n",
    "    # print(f\"  N(deme0)         :  {lower_pu[0]:.1f} - {upper_pu[0]:.1f}\")\n",
    "    # print(f\"  N(deme1)         :  {lower_pu[1]:.1f} - {upper_pu[1]:.1f}\")\n",
    "    # print(f\"  Div. time (gen)  :  {lower_pu[2]:.1f} - {upper_pu[2]:.1f}\")\n",
    "    # print(f\"  Migration rate   :  {lower_pu[3]:.6f} - {upper_pu[3]:.6f}\")\n",
    "    # print(f\"  N(ancestral)     :  {lower_pu[4]:.1f} - {upper_pu[4]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best fit parameters:\")\n",
    "print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import msprime\n",
    "import moments\n",
    "import demes\n",
    "import ray\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './data/*.vcf.gz': No such file or directory\n",
      "rm: cannot remove './data/*.h5': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert msprime.__version__ >= \"1\"\n",
    "\n",
    "if not os.path.isdir(\"./data/\"):\n",
    "    os.makedirs(\"./data/\")\n",
    "os.system(\"rm ./data/*.vcf.gz\")\n",
    "os.system(\"rm ./data/*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound_params = {\n",
    "    \"t_split\": 5000, \n",
    "    \"m\": 1e-4,\n",
    "    \"N1\": 10000,\n",
    "    \"N2\": 10000,\n",
    "    \"Na\": 20000\n",
    "}\n",
    "\n",
    "lower_bound_params =  {\n",
    "    \"t_split\": 100, \n",
    "    \"m\": 1e-8,\n",
    "    \"N1\": 100,\n",
    "    \"N2\": 100,\n",
    "    \"Na\": 10000\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_params():\n",
    "    sampled_params = {}\n",
    "    for key in lower_bound_params:\n",
    "        lower_bound = lower_bound_params[key]\n",
    "        upper_bound = upper_bound_params[key]\n",
    "        sampled_value = np.random.uniform(lower_bound, upper_bound)\n",
    "\n",
    "        # Initialize adjusted_value with sampled_value by default\n",
    "        adjusted_value = sampled_value\n",
    "\n",
    "        # Check if the sampled parameter is equal to the mean of the uniform distribution\n",
    "        mean_value = (lower_bound + upper_bound) / 2\n",
    "        if sampled_value == mean_value:\n",
    "            # Add a small random value to avoid exact mean, while keeping within bounds\n",
    "            adjustment = np.random.uniform(-0.1 * (upper_bound - lower_bound), 0.1 * (upper_bound - lower_bound))\n",
    "            adjusted_value = sampled_value + adjustment\n",
    "            # Ensure the adjusted value is still within the bounds\n",
    "            adjusted_value = max(min(adjusted_value, upper_bound), lower_bound)\n",
    "\n",
    "        # Assign adjusted_value to sampled_params\n",
    "        if key == \"m\":\n",
    "            sampled_params[key] = adjusted_value\n",
    "        else:\n",
    "            sampled_params[key] = int(adjusted_value)\n",
    "\n",
    "    return sampled_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_model(sampled_params):\n",
    "\n",
    "    # Unpack the sampled parameters\n",
    "    Na, N1, N2, m, t_split = (\n",
    "        sampled_params[\"Na\"],  # Effective population size of the ancestral population\n",
    "        sampled_params[\"N1\"],  # Size of population 1 after split\n",
    "        sampled_params[\"N2\"],  # Size of population 2 after split\n",
    "        sampled_params[\"m\"],   # Migration rate between populations\n",
    "        sampled_params[\"t_split\"],  # Time of the population split (in generations)\n",
    "    )\n",
    "\n",
    "    b = demes.Builder()\n",
    "    b.add_deme(\"Na\", epochs=[dict(start_size=Na, end_time=t_split)])\n",
    "    b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=N1)])\n",
    "    b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=N2)])\n",
    "    b.add_migration(demes=[\"N1\", \"N2\"], rate=m)\n",
    "    g = b.resolve()\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_msprime_replicates(sampled_params, experiment_config, num_reps=100, L=1000000, u=1.5e-8, r=1.5e-8):\n",
    "\n",
    "    g = demographic_model(sampled_params)\n",
    "    demog = msprime.Demography.from_demes(g)\n",
    "    tree_sequences = msprime.sim_ancestry(\n",
    "        {\"N1\": experiment_config['num_samples']['N1'], \"N2\": experiment_config['num_samples']['N2']},\n",
    "        demography=demog,\n",
    "        sequence_length=experiment_config['genome_length'],\n",
    "        recombination_rate=experiment_config['recombination_rate'],\n",
    "        num_replicates=experiment_config['num_reps'],\n",
    "        random_seed=experiment_config['seed'],\n",
    "    )\n",
    "    for ii, ts in enumerate(tree_sequences):\n",
    "        ts = msprime.sim_mutations(ts, rate=u, random_seed=ii + 1)\n",
    "        vcf_name = \"./data/split_mig.{0}.vcf\".format(ii)\n",
    "        with open(vcf_name, \"w+\") as fout:\n",
    "            ts.write_vcf(fout, allow_position_zero=True)\n",
    "        os.system(f\"gzip {vcf_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_samples_and_rec_map(experiment_config):\n",
    "\n",
    "    # Define the file paths\n",
    "    samples_file = \"./data/samples.txt\"\n",
    "    flat_map_file =\"./data/flat_map.txt\"\n",
    "\n",
    "    # Open and write the sample file\n",
    "    with open(samples_file, \"w+\") as fout:\n",
    "        fout.write(\"sample\\tpop\\n\")\n",
    "\n",
    "        # Dynamically define samples based on the num_samples dictionary\n",
    "        sample_idx = 0  # Initialize sample index\n",
    "        for pop_name, sample_size in experiment_config['num_samples'].items():\n",
    "            for _ in range(sample_size):\n",
    "                fout.write(f\"tsk_{sample_idx}\\t{pop_name}\\n\")\n",
    "                sample_idx += 1\n",
    "\n",
    "    # Write the recombination map file\n",
    "    with open(flat_map_file, \"w+\") as fout:\n",
    "        fout.write(\"pos\\tMap(cM)\\n\")\n",
    "        fout.write(\"0\\t0\\n\")\n",
    "        fout.write(f\"{experiment_config['genome_length']}\\t{experiment_config['recombination_rate'] * experiment_config['genome_length'] * 100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your function with Ray's remote decorator\n",
    "@ray.remote\n",
    "def get_LD_stats(rep_ii, r_bins):\n",
    "    vcf_file = f\"./data/split_mig.{rep_ii}.vcf.gz\"\n",
    "    time1 = time.time()\n",
    "    ld_stats = moments.LD.Parsing.compute_ld_statistics(\n",
    "        vcf_file,\n",
    "        rec_map_file=\"./data/flat_map.txt\",\n",
    "        pop_file=\"./data/samples.txt\",\n",
    "        pops=[\"N1\", \"N2\"],\n",
    "        r_bins=r_bins,\n",
    "        report=False,\n",
    "    )\n",
    "    time2 = time.time()\n",
    "    print(\"  finished rep\", rep_ii, \"in\", int(time2 - time1), \"seconds\")\n",
    "    return ld_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 10:35:55,246\tINFO worker.py:1614 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running msprime and writing vcfs\n",
      "writing samples and recombination map\n",
      "parsing LD statistics in parallel\n",
      "computing mean and varcov matrix from LD statistics sums\n",
      "computing bootstrap replicates of mean statistics (for confidence intervals\n",
      "running inference\n",
      "Simulated parameters:\n",
      "  N(deme0)         :  199.0\n",
      "  N(deme1)         :  6165.0\n",
      "  Div. time (gen)  :  2755.0\n",
      "  Migration rate   :  0.000070\n",
      "  N(ancestral)     :  18663.0\n",
      "best fit parameters:\n",
      "  N(deme0)         :  1.6\n",
      "  N(deme1)         :  325.8\n",
      "  Div. time (gen)  :  4.5\n",
      "  Migration rate   :  0.008037\n",
      "  N(ancestral)     :  6836.8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_reps = 100\n",
    "    # define the bin edges\n",
    "    r_bins = np.array([0, 1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3])\n",
    "\n",
    "    with open(\"/sietch_colab/akapoor/Demographic_Inference/experiment_config.json\") as f:\n",
    "        experiment_config = json.load(f)\n",
    "\n",
    "\n",
    "    # Initialize Ray\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    # Sample parameters\n",
    "    sampled_params = sample_params()\n",
    "\n",
    "    print(\"running msprime and writing vcfs\")\n",
    "    run_msprime_replicates(sampled_params, experiment_config)\n",
    "    # run_msprime_replicates(experiment_config=experiment_config, num_reps=num_reps)\n",
    "\n",
    "    print(\"writing samples and recombination map\")\n",
    "    write_samples_and_rec_map(experiment_config=experiment_config)\n",
    "\n",
    "    print(\"parsing LD statistics in parallel\")\n",
    "    # Submit tasks to Ray in parallel using .remote()\n",
    "    futures = [get_LD_stats.remote(ii, r_bins) for ii in range(num_reps)]\n",
    "    # Gather results with ray.get() to collect them once the tasks are finished\n",
    "    ld_stats = ray.get(futures)\n",
    "    # Optionally, you can convert the list of results into a dictionary with indices\n",
    "    ld_stats_dict = {ii: result for ii, result in enumerate(ld_stats)}\n",
    "\n",
    "    print(\"computing mean and varcov matrix from LD statistics sums\")\n",
    "    mv = moments.LD.Parsing.bootstrap_data(ld_stats_dict)\n",
    "    with open(f\"./data/means.varcovs.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(mv, fout)\n",
    "    print(\n",
    "        \"computing bootstrap replicates of mean statistics (for confidence intervals\"\n",
    "    )\n",
    "    all_boot = moments.LD.Parsing.get_bootstrap_sets(ld_stats_dict)\n",
    "    with open(f\"./data/bootstrap_sets.split_mig.{num_reps}_reps.bp\", \"wb+\") as fout:\n",
    "        pickle.dump(all_boot, fout)\n",
    "    os.system(\"rm ./data/*.vcf.gz\")\n",
    "    os.system(\"rm ./data/*.h5\")\n",
    "\n",
    "    g = demographic_model(sampled_params)\n",
    "\n",
    "    print(\"running inference\")\n",
    "    # Run inference using the parsed data\n",
    "    demo_func = moments.LD.Demographics2D.split_mig\n",
    "    # Set up the initial guess\n",
    "    # The split_mig function takes four parameters (nu0, nu1, T, m), and we append\n",
    "    # the last parameter to fit Ne, which doesn't get passed to the function but\n",
    "    # scales recombination rates so can be simultaneously fit\n",
    "    p_guess = [0.1, 2, 0.075, 2, 10000]\n",
    "    p_guess = moments.LD.Util.perturb_params(p_guess, fold=0.1)\n",
    "    opt_params, LL = moments.LD.Inference.optimize_log_lbfgsb(\n",
    "        p_guess, [mv[\"means\"], mv[\"varcovs\"]], [demo_func], rs=r_bins,\n",
    "    )\n",
    "\n",
    "    physical_units = moments.LD.Util.rescale_params(\n",
    "        opt_params, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"]\n",
    "    )\n",
    "\n",
    "    print(\"Simulated parameters:\")\n",
    "    print(f\"  N(deme0)         :  {g.demes[1].epochs[0].start_size:.1f}\")\n",
    "    print(f\"  N(deme1)         :  {g.demes[2].epochs[0].start_size:.1f}\")\n",
    "    print(f\"  Div. time (gen)  :  {g.demes[1].epochs[0].start_time:.1f}\")\n",
    "    print(f\"  Migration rate   :  {g.migrations[0].rate:.6f}\")\n",
    "    print(f\"  N(ancestral)     :  {g.demes[0].epochs[0].start_size:.1f}\")\n",
    "\n",
    "    print(\"best fit parameters:\")\n",
    "    print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "    print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "    print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "    print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "    print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
