{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MomentsLD makes me sad :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to update this notebook w.r.t. the changes that I made last week (or this week, I can't remember)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moments\n",
    "import numpy as np\n",
    "import msprime\n",
    "import demes\n",
    "import json\n",
    "os.chdir('/sietch_colab/akapoor/Demographic_Inference')\n",
    "import src.demographic_models as demographic_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see what's going wrong with my MomentsLD specific scripts. I will copy and paste them here and will debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions in the preprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_params(lower_bound_params, upper_bound_params):\n",
    "    sampled_params = {}\n",
    "    for key in lower_bound_params:\n",
    "        lower_bound = lower_bound_params[key]\n",
    "        upper_bound = upper_bound_params[key]\n",
    "        sampled_value = np.random.uniform(lower_bound, upper_bound)\n",
    "        sampled_params[key] = int(sampled_value)\n",
    "\n",
    "\n",
    "        # Check if the sampled parameter is equal to the mean of the uniform distribution\n",
    "        mean_value = (lower_bound + upper_bound) / 2\n",
    "        if sampled_value == mean_value:\n",
    "            # Add a small random value to avoid exact mean, while keeping within bounds\n",
    "            adjustment = np.random.uniform(-0.1 * (upper_bound - lower_bound), 0.1 * (upper_bound - lower_bound))\n",
    "            adjusted_value = sampled_value + adjustment\n",
    "            \n",
    "            # Ensure the adjusted value is still within the bounds\n",
    "            adjusted_value = max(min(adjusted_value, upper_bound), lower_bound)\n",
    "            sampled_params[key] = int(adjusted_value)\n",
    "\n",
    "    return sampled_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_chromosome(experiment_config, sampled_params, num_samples, demographic_model, length=1e7, mutation_rate=5.7e-9, recombination_rate = 3.386e-9, **kwargs):\n",
    "    g = demographic_model(sampled_params)\n",
    "\n",
    "    demog = msprime.Demography.from_demes(g)\n",
    "\n",
    "    # Dynamically define the samples using msprime.SampleSet, based on the sample_sizes dictionary\n",
    "    samples = [\n",
    "        msprime.SampleSet(sample_size, population=pop_name, ploidy=1)\n",
    "        for pop_name, sample_size in num_samples.items()\n",
    "    ]\n",
    "\n",
    "    # Simulate ancestry for two populations (joint simulation)\n",
    "    ts = msprime.sim_ancestry(\n",
    "        samples=samples,  # Two populations\n",
    "        demography=demog,\n",
    "        sequence_length=length,\n",
    "        recombination_rate=recombination_rate,\n",
    "        random_seed=experiment_config['seed'],\n",
    "    )\n",
    "    \n",
    "    # Simulate mutations over the ancestry tree sequence\n",
    "    ts = msprime.sim_mutations(ts, rate=mutation_rate)\n",
    "\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_window(ts, window_length, n_samples):\n",
    "    start = np.random.randint(0, n_samples - window_length)\n",
    "    end = start + window_length\n",
    "    return ts.keep_intervals([[start, end]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_msprime_replicates(ts, experiment_config, window_number, folderpath):\n",
    "\n",
    "    folderpath = os.path.join(folderpath, f\"window_{window_number}\")\n",
    "\n",
    "    # Create directory for storing VCFs\n",
    "    os.makedirs(folderpath, exist_ok=True)\n",
    "\n",
    "    # Generate random windows\n",
    "    window = generate_window(ts, experiment_config['window_length'], experiment_config['genome_length'])\n",
    "\n",
    "    # List to store file paths of the generated VCFs\n",
    "    vcf_filepath = []\n",
    "\n",
    "    # Iterate over windows and write VCFs\n",
    "    vcf_name = os.path.join(folderpath, f'window.{window_number}.vcf')\n",
    "    with open(vcf_name, \"w+\") as fout:\n",
    "        window.write_vcf(fout, allow_position_zero=True)\n",
    "        \n",
    "    # Compress the VCF file\n",
    "    os.system(f\"gzip {vcf_name}\")\n",
    "    \n",
    "    # # Store the compressed VCF file path\n",
    "    vcf_filepath.append(f\"{vcf_name}.gz\")\n",
    "    \n",
    "    # Write the metadata file with all VCF file paths\n",
    "    metadata_file = os.path.join(folderpath, \"individual_file_metadata.txt\")\n",
    "    with open(metadata_file, \"w+\") as metafile:\n",
    "        metafile.write(vcf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_samples_and_rec_map(experiment_config, window_number, folderpath):\n",
    "\n",
    "    folderpath = os.path.join(folderpath, f\"window_{window_number}\")\n",
    "\n",
    "    # Define the file paths\n",
    "    samples_file = os.path.join(folderpath, f\"samples.txt\")\n",
    "    flat_map_file = os.path.join(folderpath, f\"flat_map.txt\")\n",
    "\n",
    "    # Open and write the sample file\n",
    "    with open(samples_file, \"w+\") as fout:\n",
    "        fout.write(\"sample\\tpop\\n\")\n",
    "\n",
    "        # Dynamically define samples based on the num_samples dictionary\n",
    "        sample_idx = 0  # Initialize sample index\n",
    "        for pop_name, sample_size in experiment_config['num_samples'].items():\n",
    "            for _ in range(sample_size):\n",
    "                fout.write(f\"tsk_{sample_idx}\\t{pop_name}\\n\")\n",
    "                sample_idx += 1\n",
    "\n",
    "    # Write the recombination map file\n",
    "    with open(flat_map_file, \"w+\") as fout:\n",
    "        fout.write(\"pos\\tMap(cM)\\n\")\n",
    "        fout.write(\"0\\t0\\n\")\n",
    "        fout.write(f\"{experiment_config['genome_length']}\\t{experiment_config['recombination_rate'] * experiment_config['genome_length'] * 100}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions in the demographic_models module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_isolation_model_simulation(sampled_params):\n",
    "\n",
    "    # Unpack the sampled parameters\n",
    "    Na, N1, N2, m, t_split = (\n",
    "        sampled_params[\"Na\"],  # Effective population size of the ancestral population\n",
    "        sampled_params[\"N1\"],  # Size of population 1 after split\n",
    "        sampled_params[\"N2\"],  # Size of population 2 after split\n",
    "        sampled_params[\"m\"],   # Migration rate between populations\n",
    "        sampled_params[\"t_split\"],  # Time of the population split (in generations)\n",
    "    )\n",
    "\n",
    "    b = demes.Builder()\n",
    "    b.add_deme(\"Na\", epochs=[dict(start_size=Na, end_time=t_split)])\n",
    "    b.add_deme(\"N1\", ancestors=[\"Na\"], epochs=[dict(start_size=N1)])\n",
    "    b.add_deme(\"N2\", ancestors=[\"Na\"], epochs=[dict(start_size=N2)])\n",
    "    b.add_migration(demes=[\"N1\", \"N2\"], rate=m)\n",
    "    g = b.resolve()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for the MomentsLD inference part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your function with Ray's remote decorator\n",
    "def get_LD_stats(vcf_file, r_bins, flat_map_path, pop_file_path):\n",
    "    ld_stats = moments.LD.Parsing.compute_ld_statistics( #type:ignore\n",
    "        vcf_file,\n",
    "        rec_map_file=flat_map_path,\n",
    "        pop_file=pop_file_path,\n",
    "        pops=[\"N1\", \"N2\"], # TODO: Change later\n",
    "        r_bins=r_bins,\n",
    "        report=False,\n",
    "    )\n",
    "\n",
    "    return ld_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ld_stats_sequential(flat_map_path, pop_file_path, metadata_path, r_bins):\n",
    "    print(\"=== Computing LD statistics sequentially ===\")\n",
    "    # Debugging: Print the path to check if it's correct\n",
    "    print(f\"Looking for metadata file at: {metadata_path}\")\n",
    "\n",
    "    # Check if the file exists before trying to open it\n",
    "    if not os.path.exists(metadata_path):\n",
    "        print(f\"Error: Metadata file not found at {metadata_path}\")\n",
    "    else:\n",
    "        print(f\"Metadata file found at {metadata_path}, proceeding to open it...\")\n",
    "\n",
    "        # Try opening the file and read its contents\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                vcf_files = [line.strip() for line in f]\n",
    "            \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while reading metadata file: {str(e)}\")\n",
    "\n",
    "    # List to store LD statistics results\n",
    "    ld_stats_list = []\n",
    "\n",
    "    # Sequentially compute LD statistics for each VCF file\n",
    "    for vcf_file in vcf_files:\n",
    "        ld_stats = get_LD_stats(vcf_file, r_bins, flat_map_path, pop_file_path)\n",
    "        ld_stats_list.append(ld_stats)\n",
    "    \n",
    "    return ld_stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_momentsLD(ld_stats, demographic_model, p_guess):\n",
    "    \"\"\"\n",
    "    This should do the parameter inference for momentsLD\n",
    "    index: unique simulation number\n",
    "    \"\"\"\n",
    "\n",
    "    r_bins = np.array([0, 1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3])\n",
    "    ll_list = []\n",
    "    opt_params_dict_list = []\n",
    "\n",
    "    # print(\"computing mean and varcov matrix from LD statistics sums\")\n",
    "    # i could also job array this but let's see. \n",
    "    mv = moments.LD.Parsing.bootstrap_data(ld_stats)  # type: ignore\n",
    "    # print(\"SHAPE OF THE COVARIANCE MATRIX\")\n",
    "    # print(mv[\"varcovs\"][-1].shape)\n",
    "    # mv[\"varcovs\"][-1].shape = (1, 1)\n",
    "\n",
    "    if demographic_model == \"bottleneck_model\":\n",
    "        demo_func = moments.LD.Demographics1D.three_epoch # type: ignore\n",
    "\n",
    "    elif demographic_model == \"split_isolation_model\":\n",
    "        demo_func = demographic_models.split_isolation_model_momentsLD\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported demographic model: {demographic_model}\")\n",
    "\n",
    "    opt_params, ll = moments.LD.Inference.optimize_log_lbfgsb( #type:ignore\n",
    "    p_guess, [mv[\"means\"], mv[\"varcovs\"]], [demo_func], rs=r_bins, verbose = 3\n",
    "    )\n",
    "\n",
    "    physical_units = moments.LD.Util.rescale_params( # type: ignore\n",
    "        opt_params, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"]\n",
    "    )\n",
    "    ll_list.append(ll)\n",
    "\n",
    "    opt_params_dict = {}\n",
    "    if demographic_model == \"bottleneck_model\":\n",
    "\n",
    "        opt_params_dict = {\n",
    "            # \"N0\": opt_params[4],\n",
    "            \"Nb\": opt_params[0] * opt_params[4],\n",
    "            \"N_recover\": opt_params[1] * opt_params[4],\n",
    "            \"t_bottleneck_start\": (opt_params[2]+opt_params[3]) * 2 * opt_params[4],\n",
    "            \"t_bottleneck_end\": opt_params[3] * 2 * opt_params[4]\n",
    "        }\n",
    "\n",
    "    elif demographic_model == \"split_isolation_model\":\n",
    "        physical_units = moments.LD.Util.rescale_params( #type:ignore\n",
    "            opt_params, [\"nu\", \"nu\", \"T\", \"m\", \"Ne\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "        print(physical_units)\n",
    "\n",
    "        opt_params_dict = {\n",
    "            \"N1\": physical_units[0],\n",
    "            \"N2\": physical_units[1],\n",
    "            \"t_split\": physical_units[2],\n",
    "            \"m\": physical_units[3], \n",
    "            'Na': physical_units[4]\n",
    "        }\n",
    "\n",
    "        print(\"best fit parameters:\")\n",
    "        print(f\"  N(deme0)         :  {physical_units[0]:.1f}\")\n",
    "        print(f\"  N(deme1)         :  {physical_units[1]:.1f}\")\n",
    "        print(f\"  Div. time (gen)  :  {physical_units[2]:.1f}\")\n",
    "        print(f\"  Migration rate   :  {physical_units[3]:.6f}\")\n",
    "        print(f\"  N(ancestral)     :  {physical_units[4]:.1f}\")\n",
    "\n",
    "        opt_params_dict_list.append(opt_params_dict)\n",
    "\n",
    "    return opt_params_dict_list, ll_list \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the experiment_config.json\n",
    "with open(\"/sietch_colab/akapoor/Demographic_Inference/experiment_config.json\", \"r\") as f:\n",
    "    experiment_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/sietch_colab/akapoor/Demographic_Inference/sampled_params_2.pkl', 'rb') as f:\n",
    "    sampled_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the .trees file\n",
    "import tskit\n",
    "ts = tskit.load(\"/sietch_colab/akapoor/Demographic_Inference/ts_sim_2.trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t_split': 1296, 'N1': 325, 'N2': 6832, 'Na': 16297, 'm': 0}\n"
     ]
    }
   ],
   "source": [
    "# sampled_params = sample_params(experiment_config[\"lower_bound_params\"], experiment_config[\"upper_bound_params\"])\n",
    "print(sampled_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "              <style>\n",
       "                .tskit-table thead tr th {text-align: left;padding: 0.5em 0.5em;}\n",
       "                .tskit-table tbody tr td {padding: 0.5em 0.5em;}\n",
       "                .tskit-table tbody tr td:first-of-type {text-align: left;}\n",
       "                .tskit-details-label {vertical-align: top; padding-right:5px;}\n",
       "                .tskit-table-set {display: inline-flex;flex-wrap: wrap;margin: -12px 0 0 -12px;width: calc(100% + 12px);}\n",
       "                .tskit-table-set-table {margin: 12px 0 0 12px;}\n",
       "                details {display: inline-block;}\n",
       "                summary {cursor: pointer; outline: 0; display: list-item;}\n",
       "              </style>\n",
       "              <div class=\"tskit-table-set\">\n",
       "                <div class=\"tskit-table-set-table\">\n",
       "                  <table class=\"tskit-table\">\n",
       "                    <thead>\n",
       "                      <tr>\n",
       "                        <th style=\"padding:0;line-height:21px;\">\n",
       "                          <img style=\"height: 32px;display: inline-block;padding: 3px 5px 3px 0;\" src=\"https://raw.githubusercontent.com/tskit-dev/administrative/main/tskit_logo.svg\"/>\n",
       "                          <a target=\"_blank\" href=\"https://tskit.dev/tskit/docs/latest/python-api.html#the-treesequence-class\"> Tree Sequence </a>\n",
       "                        </th>\n",
       "                      </tr>\n",
       "                    </thead>\n",
       "                    <tbody>\n",
       "                      <tr><td>Trees</td><td>265380</td></tr>\n",
       "                      <tr><td>Sequence Length</td><td>100000000.0</td></tr>\n",
       "                      <tr><td>Time Units</td><td>generations</td></tr>\n",
       "                      <tr><td>Sample Nodes</td><td>40</td></tr>\n",
       "                      <tr><td>Total Size</td><td>56.8 MiB</td></tr>\n",
       "                      <tr>\n",
       "                        <td>Metadata</td><td style=\"text-align: left;\">No Metadata</td></tr>\n",
       "                    </tbody>\n",
       "                  </table>\n",
       "                </div>\n",
       "                <div class=\"tskit-table-set-table\">\n",
       "                  <table class=\"tskit-table\">\n",
       "                    <thead>\n",
       "                      <tr>\n",
       "                        <th style=\"line-height:21px;\">Table</th>\n",
       "                        <th>Rows</th>\n",
       "                        <th>Size</th>\n",
       "                        <th>Has Metadata</th>\n",
       "                      </tr>\n",
       "                    </thead>\n",
       "                    <tbody>\n",
       "                    \n",
       "                  <tr>\n",
       "                    <td>Edges</td>\n",
       "                      <td>859588</td>\n",
       "                      <td>26.2 MiB</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Individuals</td>\n",
       "                      <td>40</td>\n",
       "                      <td>1.1 KiB</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Migrations</td>\n",
       "                      <td>0</td>\n",
       "                      <td>8 Bytes</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Mutations</td>\n",
       "                      <td>327909</td>\n",
       "                      <td>11.6 MiB</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Nodes</td>\n",
       "                      <td>173995</td>\n",
       "                      <td>4.6 MiB</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Populations</td>\n",
       "                      <td>3</td>\n",
       "                      <td>297 Bytes</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        ✅\n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Provenances</td>\n",
       "                      <td>2</td>\n",
       "                      <td>2.9 KiB</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                  <tr>\n",
       "                    <td>Sites</td>\n",
       "                      <td>327260</td>\n",
       "                      <td>7.8 MiB</td>\n",
       "                      <td style=\"text-align: center;\">\n",
       "                        \n",
       "                      </td>\n",
       "                    </tr>\n",
       "                \n",
       "                    </tbody>\n",
       "                  </table>\n",
       "                </div>\n",
       "              </div>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<tskit.trees.TreeSequence at 0x7f4f49f32320>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = f\"/sietch_colab/akapoor/Demographic_Inference/testing_things/simulations/{experiment_config['demographic_model']}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_model = \"split_isolation_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_guess = [0.02, 0.42, 0.075, 0.01, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LD stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_stats = {}\n",
    "base_dir = '/sietch_colab/akapoor/Demographic_Inference/sim_2'\n",
    "absolute_paths = [os.path.abspath(os.path.join(base_dir, f)) for f in os.listdir(base_dir)]\n",
    "\n",
    "for i in range(len(absolute_paths)):\n",
    "    with open(absolute_paths[i], 'rb') as f:\n",
    "        ld_stats[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02, 0.42, 0.075, 0.01, 10000]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "357     , -9.57786e+10, array([ 0.02       ,  0.42042    ,  0.075      ,  0.01       ,  10000      ])\n",
      "360     , -9.58562e+10, array([ 0.02       ,  0.42       ,  0.075      ,  0.01       ,  10010      ])\n",
      "363     , -1.75719e+07, array([ 0.0396795  ,  0.433339   ,  0.0362608  ,  0.0100312  ,  9614.8     ])\n",
      "366     , -1.75745e+07, array([ 0.0396795  ,  0.432906   ,  0.0362608  ,  0.0100312  ,  9624.41    ])\n",
      "369     , -1.75582e+07, array([ 0.0396826  ,  0.433342   ,  0.0362579  ,  0.0100312  ,  9614.82    ])\n",
      "372     , -1.75607e+07, array([ 0.0396826  ,  0.432908   ,  0.0362579  ,  0.0100312  ,  9624.44    ])\n",
      "375     , -1.75032e+07, array([ 0.0396948  ,  0.433351   ,  0.0362464  ,  0.0100312  ,  9614.94    ])\n",
      "378     , -1.75057e+07, array([ 0.0396948  ,  0.432917   ,  0.0362464  ,  0.0100312  ,  9624.56    ])\n",
      "381     , -1.72852e+07, array([ 0.0397439  ,  0.433387   ,  0.0362001  ,  0.0100313  ,  9615.39    ])\n",
      "384     , -1.72877e+07, array([ 0.0397439  ,  0.432954   ,  0.0362001  ,  0.0100313  ,  9625.01    ])\n",
      "387     , -1.64422e+07, array([ 0.0399408  ,  0.433531   ,  0.0360158  ,  0.0100313  ,  9617.2     ])\n",
      "390     , -1.64444e+07, array([ 0.0399408  ,  0.433098   ,  0.0360158  ,  0.0100313  ,  9626.82    ])\n",
      "393     , -1.34906e+07, array([ 0.0407383  ,  0.43411    ,  0.0352878  ,  0.0100314  ,  9624.46    ])\n",
      "396     , -1.3492e+07 , array([ 0.0407383  ,  0.433676   ,  0.0352878  ,  0.0100314  ,  9634.09    ])\n",
      "399     , -6.40016e+06, array([ 0.0440955  ,  0.436549   ,  0.0325322  ,  0.0100319  ,  9676.48    ])\n",
      "402     , -6.39995e+06, array([ 0.0440955  ,  0.436112   ,  0.0325322  ,  0.0100319  ,  9686.16    ])\n",
      "405     , -3.93869e+06, array([ 0.0467624  ,  0.438442   ,  0.030654   ,  0.0100321  ,  9746.58    ])\n",
      "408     , -3.938e+06  , array([ 0.0467624  ,  0.438004   ,  0.030654   ,  0.0100321  ,  9756.33    ])\n",
      "411     , -2.45294e+06, array([ 0.0500992  ,  0.440656   ,  0.0286379  ,  0.0100323  ,  9884.72    ])\n",
      "414     , -2.45204e+06, array([ 0.0500992  ,  0.440216   ,  0.0286379  ,  0.0100323  ,  9894.61    ])\n",
      "417     , -1.69484e+06, array([ 0.0537244  ,  0.442699   ,  0.02682    ,  0.0100324  ,  10122.6    ])\n",
      "420     , -1.69389e+06, array([ 0.0537244  ,  0.442256   ,  0.02682    ,  0.0100324  ,  10132.8    ])\n",
      "423     , -1.23662e+06, array([ 0.0582087  ,  0.444447   ,  0.0250345  ,  0.0100323  ,  10582.5    ])\n",
      "426     , -1.2357e+06 , array([ 0.0582087  ,  0.444003   ,  0.0250345  ,  0.0100323  ,  10593.1    ])\n",
      "429     , -919956     , array([ 0.0642111  ,  0.445301   ,  0.0232711  ,  0.010032   ,  11521.2    ])\n",
      "432     , -919140     , array([ 0.0642111  ,  0.444856   ,  0.0232711  ,  0.010032   ,  11532.7    ])\n",
      "435     , -649232     , array([ 0.0734469  ,  0.444136   ,  0.0214534  ,  0.0100315  ,  13656.3    ])\n",
      "438     , -648596     , array([ 0.0734469  ,  0.443692   ,  0.0214534  ,  0.0100315  ,  13670      ])\n",
      "441     , -413422     , array([ 0.0878579  ,  0.439409   ,  0.0197547  ,  0.0100308  ,  18677      ])\n",
      "444     , -413009     , array([ 0.0878579  ,  0.43897    ,  0.0197547  ,  0.0100308  ,  18695.7    ])\n",
      "447     , -259835     , array([ 0.104909   ,  0.432094   ,  0.0187205  ,  0.0100303  ,  28764      ])\n",
      "450     , -259594     , array([ 0.104909   ,  0.431662   ,  0.0187205  ,  0.0100303  ,  28792.8    ])\n",
      "453     , -173563     , array([ 0.118538   ,  0.423525   ,  0.0187544  ,  0.0100302  ,  47165.7    ])\n",
      "456     , -173424     , array([ 0.118538   ,  0.423102   ,  0.0187544  ,  0.0100302  ,  47212.9    ])\n",
      "459     , -112359     , array([ 0.123356   ,  0.410385   ,  0.0204603  ,  0.01003    ,  86462.7    ])\n",
      "462     , -112286     , array([ 0.123356   ,  0.409975   ,  0.0204603  ,  0.01003    ,  86549.2    ])\n",
      "465     , -76555.4    , array([ 0.113657   ,  0.391216   ,  0.0245594  ,  0.0100288  ,  172397     ])\n",
      "468     , -76530.9    , array([ 0.113657   ,  0.390825   ,  0.0245594  ,  0.0100288  ,  172570     ])\n",
      "471     , -71347.4    , array([ 0.115357   ,  0.386868   ,  0.0248529  ,  0.010029   ,  228564     ])\n",
      "474     , -71336.4    , array([ 0.115357   ,  0.386481   ,  0.0248529  ,  0.010029   ,  228793     ])\n",
      "477     , -69345.6    , array([ 0.114803   ,  0.378054   ,  0.0233976  ,  0.0100301  ,  284492     ])\n",
      "480     , -69340.6    , array([ 0.114803   ,  0.377677   ,  0.0233976  ,  0.0100301  ,  284776     ])\n",
      "483     , -69147.5    , array([ 0.113015   ,  0.372672   ,  0.0231509  ,  0.0100304  ,  307288     ])\n",
      "486     , -69144.9    , array([ 0.113015   ,  0.372299   ,  0.0231509  ,  0.0100304  ,  307596     ])\n",
      "489     , -68842      , array([ 0.107737   ,  0.354546   ,  0.0220735  ,  0.0100311  ,  324688     ])\n",
      "492     , -68840.7    , array([ 0.107737   ,  0.354192   ,  0.0220735  ,  0.0100311  ,  325013     ])\n",
      "495     , -66627.2    , array([ 0.0658196  ,  0.209773   ,  0.0132623  ,  0.0100389  ,  472834     ])\n",
      "498     , -66631.9    , array([ 0.0658196  ,  0.209563   ,  0.0132623  ,  0.0100389  ,  473307     ])\n",
      "501     , -64555.6    , array([ 0.0354234  ,  0.103685   ,  0.00690569 ,  0.0100484  ,  644417     ])\n",
      "504     , -64564.3    , array([ 0.0354234  ,  0.103581   ,  0.00690569 ,  0.0100484  ,  645062     ])\n",
      "507     , -62022.1    , array([ 0.0167746  ,  0.0491231  ,  0.00319653 ,  0.0100555  ,  740448     ])\n",
      "510     , -62029.5    , array([ 0.0167746  ,  0.049074   ,  0.00319653 ,  0.0100555  ,  741188     ])\n",
      "513     , -59534.7    , array([ 0.00757644 ,  0.0191777  ,  0.00131616 ,  0.0100602  ,  716058     ])\n",
      "516     , -59542.4    , array([ 0.00757644 ,  0.0191586  ,  0.00131616 ,  0.0100602  ,  716774     ])\n",
      "519     , -58537.5    , array([ 0.00729414 ,  0.0195365  ,  0.00130184 ,  0.010057   ,  555905     ])\n",
      "522     , -58540.9    , array([ 0.00729414 ,  0.019517   ,  0.00130184 ,  0.010057   ,  556461     ])\n",
      "525     , -58402.4    , array([ 0.00771235 ,  0.0214667  ,  0.0013672  ,  0.0100555  ,  520174     ])\n",
      "528     , -58402.9    , array([ 0.00771235 ,  0.0214453  ,  0.0013672  ,  0.0100555  ,  520695     ])\n",
      "531     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "534     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "537     , -58404.5    , array([ 0.00752401 ,  0.0213226  ,  0.00133266 ,  0.0100559  ,  525045     ])\n",
      "540     , -58404.5    , array([ 0.00752401 ,  0.0213013  ,  0.00133266 ,  0.0100559  ,  525570     ])\n",
      "543     , -58399.2    , array([ 0.00763432 ,  0.0215079  ,  0.00135199 ,  0.0100557  ,  523909     ])\n",
      "546     , -58399.3    , array([ 0.00763432 ,  0.0214864  ,  0.00135199 ,  0.0100557  ,  524433     ])\n",
      "549     , -58398.9    , array([ 0.00764095 ,  0.021519   ,  0.00135315 ,  0.0100557  ,  523841     ])\n",
      "552     , -58399.1    , array([ 0.00764095 ,  0.0214975  ,  0.00135315 ,  0.0100557  ,  524365     ])\n",
      "555     , -58398.9    , array([ 0.00764137 ,  0.0215197  ,  0.00135322 ,  0.0100557  ,  523837     ])\n",
      "558     , -58399.1    , array([ 0.00764137 ,  0.0214982  ,  0.00135322 ,  0.0100557  ,  524361     ])\n",
      "561     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135322 ,  0.0100557  ,  523837     ])\n",
      "564     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135322 ,  0.0100557  ,  524361     ])\n",
      "567     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "570     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "573     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "576     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "579     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "582     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "585     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "588     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "591     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "594     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "597     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "600     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "603     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "606     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "609     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "612     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "615     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "618     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "621     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "624     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "627     , -58398.9    , array([ 0.0076414  ,  0.0215198  ,  0.00135323 ,  0.0100557  ,  523837     ])\n",
      "630     , -58399.1    , array([ 0.0076414  ,  0.0214983  ,  0.00135323 ,  0.0100557  ,  524361     ])\n",
      "[4.00284556e+03 1.12615826e+04 1.41773786e+03 9.59808974e-09\n",
      " 5.23836586e+05]\n",
      "best fit parameters:\n",
      "  N(deme0)         :  4002.8\n",
      "  N(deme1)         :  11261.6\n",
      "  Div. time (gen)  :  1417.7\n",
      "  Migration rate   :  0.000000\n",
      "  N(ancestral)     :  523836.6\n"
     ]
    }
   ],
   "source": [
    "opt_params_dict, ll_list = run_inference_momentsLD(ld_stats, demographic_model, p_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58399.109329996245]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing stuff from scratch again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect there could be wrong with something with SLURM, which would cause these issues ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.demographic_models import split_isolation_model_simulation\n",
    "\n",
    "demographic_model = split_isolation_model_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = simulate_chromosome(experiment_config, sampled_params, experiment_config['num_samples'], demographic_model, length=experiment_config['genome_length'], mutation_rate=experiment_config['mutation_rate'], recombination_rate = experiment_config['recombination_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for window_number in tqdm(range(experiment_config['num_windows'])):\n",
    "\n",
    "    run_msprime_replicates(ts, experiment_config, window_number, folderpath = 'sampled_genome_windows')\n",
    "    write_samples_and_rec_map(experiment_config, window_number, folderpath = 'sampled_genome_windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_stats_all = {}\n",
    "\n",
    "r_bins = np.array([0, 1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3])\n",
    "\n",
    "for i in tqdm(range(experiment_config['num_windows'])):\n",
    "\n",
    "    vcf_file = f'/sietch_colab/akapoor/Demographic_Inference/sampled_genome_windows/window_{i}/window.{i}.vcf.gz'\n",
    "    flat_map_path = f'/sietch_colab/akapoor/Demographic_Inference/sampled_genome_windows/window_{i}/flat_map.txt'\n",
    "    pop_file_path = f'/sietch_colab/akapoor/Demographic_Inference/sampled_genome_windows/window_{i}/samples.txt'\n",
    "\n",
    "    ld_stats = get_LD_stats(vcf_file=vcf_file, r_bins=r_bins, flat_map_path=flat_map_path, pop_file_path=pop_file_path)\n",
    "    ld_stats_all[i] = ld_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_guess = [0.2, 0.3, 0.08, 0.25, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.demographic_models import split_isolation_model_momentsLD\n",
    "demographic_model = \"split_isolation_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_dict_list, ll_list = run_inference_momentsLD(ld_stats_all, demographic_model, p_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_dict_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['upper_bound_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['lower_bound_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dadi makes me sad :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moments\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import msprime\n",
    "import dadi\n",
    "import glob\n",
    "import demes\n",
    "import ray\n",
    "import json\n",
    "os.chdir('/sietch_colab/akapoor/Demographic_Inference')\n",
    "import src.demographic_models as demographic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the experiment_config.json\n",
    "with open(\"/sietch_colab/akapoor/Demographic_Inference/experiment_config.json\", \"r\") as f:\n",
    "    experiment_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_params(lower_bound_params, upper_bound_params):\n",
    "    sampled_params = {}\n",
    "    for key in lower_bound_params:\n",
    "        lower_bound = lower_bound_params[key]\n",
    "        upper_bound = upper_bound_params[key]\n",
    "        sampled_value = np.random.uniform(lower_bound, upper_bound)\n",
    "        sampled_params[key] = int(sampled_value)\n",
    "\n",
    "\n",
    "        # Check if the sampled parameter is equal to the mean of the uniform distribution\n",
    "        mean_value = (lower_bound + upper_bound) / 2\n",
    "        if sampled_value == mean_value:\n",
    "            # Add a small random value to avoid exact mean, while keeping within bounds\n",
    "            adjustment = np.random.uniform(-0.1 * (upper_bound - lower_bound), 0.1 * (upper_bound - lower_bound))\n",
    "            adjusted_value = sampled_value + adjustment\n",
    "            \n",
    "            # Ensure the adjusted value is still within the bounds\n",
    "            adjusted_value = max(min(adjusted_value, upper_bound), lower_bound)\n",
    "            sampled_params[key] = int(adjusted_value)\n",
    "\n",
    "    return sampled_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_params = sample_params(experiment_config[\"lower_bound_params\"], experiment_config[\"upper_bound_params\"])\n",
    "print(sampled_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SFS(\n",
    "    experiment_config, sampled_params, mode, num_samples, demographic_model, length=1e7, mutation_rate=5.7e-9, recombination_rate = 3.386e-9, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    If we are in pretraining mode we will use a simulated SFS. If we are in inference mode we will use a real SFS.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if mode == \"pretrain\":\n",
    "        # Simulate the demographic model\n",
    "        g = demographic_model(sampled_params)\n",
    "        demog = msprime.Demography.from_demes(g)\n",
    "\n",
    "        # Dynamically define the samples using msprime.SampleSet, based on the sample_sizes dictionary\n",
    "        samples = [\n",
    "            msprime.SampleSet(sample_size, population=pop_name, ploidy=1)\n",
    "            for pop_name, sample_size in num_samples.items()\n",
    "        ]\n",
    "\n",
    "        # Simulate ancestry for two populations (joint simulation)\n",
    "        ts = msprime.sim_ancestry(\n",
    "            samples=samples,  # Two populations\n",
    "            demography=demog,\n",
    "            sequence_length=length,\n",
    "            recombination_rate=recombination_rate,\n",
    "            random_seed=experiment_config['seed'],\n",
    "        )\n",
    "        \n",
    "        # Simulate mutations over the ancestry tree sequence\n",
    "        ts = msprime.sim_mutations(ts, rate=mutation_rate)\n",
    "\n",
    "        # Define sample sets dynamically for the SFS\n",
    "        sample_sets = [\n",
    "            ts.samples(population=pop.id) \n",
    "            for pop in ts.populations() \n",
    "            if len(ts.samples(population=pop.id)) > 0  # Exclude populations with no samples\n",
    "        ]\n",
    "        \n",
    "        # Create the joint allele frequency spectrum\n",
    "        sfs = ts.allele_frequency_spectrum(sample_sets=sample_sets, mode=\"site\", polarised=True)\n",
    "        \n",
    "        # Multiply SFS by the sequence length to adjust scale\n",
    "        sfs *= length\n",
    "\n",
    "        # Convert to moments Spectrum for further use\n",
    "        sfs = moments.Spectrum(sfs)\n",
    "    \n",
    "    elif mode == \"inference\":\n",
    "        vcf_file = kwargs.get(\"vcf_file\", None)\n",
    "        pop_file = kwargs.get(\"pop_file\", None)\n",
    "        popname = kwargs.get(\"popname\", None)\n",
    "\n",
    "        if vcf_file is None or pop_file is None:\n",
    "            raise ValueError(\n",
    "                \"vcf_file and pop_file must be provided in inference mode.\"\n",
    "            )\n",
    "\n",
    "        dd = dadi.Misc.make_data_dict_vcf(vcf_file, pop_file)\n",
    "        sfs = dadi.Spectrum.from_data_dict(\n",
    "            dd, [popname], projections=[2 * num_samples], polarized=True\n",
    "        )\n",
    "\n",
    "    return sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = create_SFS(\n",
    "    experiment_config,\n",
    "      sampled_params,\n",
    "        \"pretrain\",\n",
    "          experiment_config[\"num_samples\"],\n",
    "            demographic_models.split_isolation_model_simulation,\n",
    "              length=experiment_config['genome_length'],\n",
    "                mutation_rate=experiment_config['mutation_rate'], recombination_rate = experiment_config['recombination_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parameter_inference import run_inference_dadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sfs_dadi, opt_theta_dadi, opt_params_dict_dadi, ll_list_dadi = (\n",
    "        run_inference_dadi(\n",
    "            sfs = sfs,\n",
    "            p0= experiment_config['optimization_initial_guess'],\n",
    "            lower_bound= experiment_config['lower_bound_optimization'],\n",
    "            upper_bound= experiment_config['upper_bound_optimization'],\n",
    "            num_samples=20,\n",
    "            demographic_model=experiment_config['demographic_model'],\n",
    "            mutation_rate=experiment_config['mutation_rate'],\n",
    "            length=experiment_config['genome_length'],\n",
    "            k  = experiment_config['k'], \n",
    "            top_values_k = experiment_config['top_values_k']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
